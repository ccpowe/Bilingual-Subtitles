#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
main.py ä½¿ç”¨ç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ä¸»æ§åˆ¶è„šæœ¬çš„å„ç§æ¨¡å¼
"""

import os
import subprocess
import sys
from pathlib import Path

def run_command(cmd: str, description: str):
    """è¿è¡Œå‘½ä»¤å¹¶æ˜¾ç¤ºç»“æœ"""
    print(f"\nğŸ”§ {description}")
    print(f"ğŸ“ å‘½ä»¤: {cmd}")
    print("-" * 50)
    
    try:
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
        if result.returncode == 0:
            print("âœ… æ‰§è¡ŒæˆåŠŸ")
            if result.stdout:
                print(result.stdout)
        else:
            print("âŒ æ‰§è¡Œå¤±è´¥")
            if result.stderr:
                print(result.stderr)
    except Exception as e:
        print(f"âŒ æ‰§è¡Œå¼‚å¸¸: {e}")

def check_environment():
    """æ£€æŸ¥ç¯å¢ƒé…ç½®"""
    print("ğŸ” ç¯å¢ƒæ£€æŸ¥")
    print("=" * 60)
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    api_key = os.getenv("OPENAI_API_KEY")
    base_url = os.getenv("MODEL_BASE_URL")
    model_name = os.getenv("MODEL_NAME")
    
    print(f"OPENAI_API_KEY: {'âœ… å·²è®¾ç½®' if api_key else 'âŒ æœªè®¾ç½®'}")
    print(f"MODEL_BASE_URL: {'âœ… å·²è®¾ç½®' if base_url else 'âšª ä½¿ç”¨é»˜è®¤'}")
    print(f"MODEL_NAME: {model_name or 'gpt-4o-mini (é»˜è®¤)'}")
    
    # æ£€æŸ¥ä¾èµ–
    try:
        import faster_whisper
        print("âœ… faster-whisper: å·²å®‰è£…")
    except ImportError:
        print("âŒ faster-whisper: æœªå®‰è£…")
    
    try:
        import langgraph
        import langchain_openai
        print("âœ… ç¿»è¯‘ä¾èµ–: å·²å®‰è£…")
    except ImportError:
        print("âŒ ç¿»è¯‘ä¾èµ–: æœªå®‰è£…")
    
    # æ£€æŸ¥ç¤ºä¾‹æ–‡ä»¶
    test_audio = "str_file/Building_Ambient_Agents_with_LangGraph_-_LangChain_Academy (1).mp4"
    test_srt = "str_file/Building_Ambient_Agents_20250629_155924.srt"
    
    print(f"\nğŸ“ ç¤ºä¾‹æ–‡ä»¶:")
    print(f"æµ‹è¯•éŸ³é¢‘: {'âœ… å­˜åœ¨' if os.path.exists(test_audio) else 'âŒ ä¸å­˜åœ¨'}")
    print(f"æµ‹è¯•SRT: {'âœ… å­˜åœ¨' if os.path.exists(test_srt) else 'âŒ ä¸å­˜åœ¨'}")

def example_dry_run():
    """ç©ºè¿è¡Œç¤ºä¾‹ - éªŒè¯é…ç½®"""
    print("\n" + "=" * 60)
    print("ğŸ” ç¤ºä¾‹1: ç©ºè¿è¡Œæ¨¡å¼ (éªŒè¯é…ç½®)")
    print("=" * 60)
    
    # æµ‹è¯•å®Œæ•´å·¥ä½œæµé…ç½®
    cmd = 'uv run python main.py "test_video.mp4" --mode full -l en -s è‹±æ–‡ -t ä¸­æ–‡ --dry-run'
    run_command(cmd, "éªŒè¯å®Œæ•´å·¥ä½œæµé…ç½®")
    
    # æµ‹è¯•ä»…è½¬å½•é…ç½®
    cmd = 'uv run python main.py "test_video.mp4" --mode transcribe -l en --auto-config --dry-run'
    run_command(cmd, "éªŒè¯è½¬å½•é…ç½®")
    
    # æµ‹è¯•ä»…ç¿»è¯‘é…ç½®
    cmd = 'uv run python main.py "test.srt" --mode translate -s è‹±æ–‡ -t ä¸­æ–‡ --dry-run'
    run_command(cmd, "éªŒè¯ç¿»è¯‘é…ç½®")

def example_transcribe_only():
    """ä»…è½¬å½•ç¤ºä¾‹"""
    print("\n" + "=" * 60)
    print("ğŸµ ç¤ºä¾‹2: ä»…éŸ³é¢‘è½¬å½•æ¨¡å¼")
    print("=" * 60)
    
    # å‡è®¾çš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„
    test_audio = "str_file/Building_Ambient_Agents_with_LangGraph_-_LangChain_Academy (1).mp4"
    
    if not os.path.exists(test_audio):
        print(f"âš ï¸ æµ‹è¯•éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {test_audio}")
        print("ğŸ’¡ è¯·æ›¿æ¢ä¸ºå®é™…çš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„")
        test_audio = "your_audio_file.mp4"
    
    commands = [
        # åŸºç¡€è½¬å½•
        f'uv run python main.py "{test_audio}" --mode transcribe -l en',
        
        # è‡ªåŠ¨é…ç½®è½¬å½•
        f'uv run python main.py "{test_audio}" --mode transcribe -l en --auto-config',
        
        # é«˜è´¨é‡è½¬å½•
        f'uv run python main.py "{test_audio}" --mode transcribe -l en -m small --compute-type float16',
        
        # å¿«é€Ÿè½¬å½•
        f'uv run python main.py "{test_audio}" --mode transcribe -l en -m tiny --compute-type int8'
    ]
    
    descriptions = [
        "åŸºç¡€è‹±æ–‡è½¬å½•",
        "è‡ªåŠ¨é…ç½®è½¬å½•",
        "é«˜è´¨é‡è½¬å½• (smallæ¨¡å‹)",
        "å¿«é€Ÿè½¬å½• (tinyæ¨¡å‹)"
    ]
    
    for cmd, desc in zip(commands, descriptions):
        print(f"\nğŸ“ {desc}:")
        print(f"å‘½ä»¤: {cmd}")

def example_translate_only():
    """ä»…ç¿»è¯‘ç¤ºä¾‹"""
    print("\n" + "=" * 60)
    print("ğŸŒ ç¤ºä¾‹3: ä»…å­—å¹•ç¿»è¯‘æ¨¡å¼")
    print("=" * 60)
    
    # å‡è®¾çš„SRTæ–‡ä»¶è·¯å¾„
    test_srt = "str_file/Building_Ambient_Agents_20250629_155924.srt"
    
    if not os.path.exists(test_srt):
        print(f"âš ï¸ æµ‹è¯•SRTæ–‡ä»¶ä¸å­˜åœ¨: {test_srt}")
        print("ğŸ’¡ è¯·å…ˆç”ŸæˆSRTæ–‡ä»¶æˆ–æ›¿æ¢ä¸ºå®é™…è·¯å¾„")
        test_srt = "your_subtitle.srt"
    
    commands = [
        # è‹±è¯‘ä¸­
        f'uv run python main.py "{test_srt}" --mode translate -s è‹±æ–‡ -t ä¸­æ–‡',
        
        # è‹±è¯‘æ—¥
        f'uv run python main.py "{test_srt}" --mode translate -s è‹±æ–‡ -t æ—¥è¯­',
        
        # å°æ‰¹é‡é«˜è´¨é‡ç¿»è¯‘
        f'uv run python main.py "{test_srt}" --mode translate -s è‹±æ–‡ -t ä¸­æ–‡ --llm-model gpt-4 -b 3',
        
        # å¤§æ‰¹é‡å¿«é€Ÿç¿»è¯‘
        f'uv run python main.py "{test_srt}" --mode translate -s è‹±æ–‡ -t ä¸­æ–‡ -b 10'
    ]
    
    descriptions = [
        "è‹±æ–‡â†’ä¸­æ–‡ç¿»è¯‘",
        "è‹±æ–‡â†’æ—¥è¯­ç¿»è¯‘",
        "é«˜è´¨é‡ç¿»è¯‘ (GPT-4, å°æ‰¹é‡)",
        "å¿«é€Ÿç¿»è¯‘ (å¤§æ‰¹é‡)"
    ]
    
    for cmd, desc in zip(commands, descriptions):
        print(f"\nğŸ“ {desc}:")
        print(f"å‘½ä»¤: {cmd}")

def example_full_workflow():
    """å®Œæ•´å·¥ä½œæµç¤ºä¾‹"""
    print("\n" + "=" * 60)
    print("ğŸš€ ç¤ºä¾‹4: å®Œæ•´å·¥ä½œæµæ¨¡å¼")
    print("=" * 60)
    
    test_audio = "str_file/Building_Ambient_Agents_with_LangGraph_-_LangChain_Academy (1).mp4"
    
    if not os.path.exists(test_audio):
        print(f"âš ï¸ æµ‹è¯•éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {test_audio}")
        print("ğŸ’¡ è¯·æ›¿æ¢ä¸ºå®é™…çš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„")
        test_audio = "your_audio_file.mp4"
    
    commands = [
        # æ ‡å‡†å®Œæ•´æµç¨‹
        f'uv run python main.py "{test_audio}" --mode full -l en -s è‹±æ–‡ -t ä¸­æ–‡',
        
        # è‡ªåŠ¨é…ç½®å®Œæ•´æµç¨‹
        f'uv run python main.py "{test_audio}" --mode full -l en -s è‹±æ–‡ -t ä¸­æ–‡ --auto-config',
        
        # é«˜è´¨é‡å®Œæ•´æµç¨‹
        f'uv run python main.py "{test_audio}" --mode full -l en -s è‹±æ–‡ -t ä¸­æ–‡ -m small --llm-model gpt-4 -b 3',
        
        # å¿«é€Ÿå®Œæ•´æµç¨‹
        f'uv run python main.py "{test_audio}" --mode full -l en -s è‹±æ–‡ -t ä¸­æ–‡ -m tiny --compute-type int8 -b 8'
    ]
    
    descriptions = [
        "æ ‡å‡†å®Œæ•´æµç¨‹",
        "è‡ªåŠ¨é…ç½®å®Œæ•´æµç¨‹",
        "é«˜è´¨é‡å®Œæ•´æµç¨‹",
        "å¿«é€Ÿå®Œæ•´æµç¨‹"
    ]
    
    for cmd, desc in zip(commands, descriptions):
        print(f"\nğŸ“ {desc}:")
        print(f"å‘½ä»¤: {cmd}")

def example_advanced_usage():
    """é«˜çº§ç”¨æ³•ç¤ºä¾‹"""
    print("\n" + "=" * 60)
    print("âš™ï¸ ç¤ºä¾‹5: é«˜çº§ç”¨æ³•")
    print("=" * 60)
    
    print("ğŸ“ è¯¦ç»†æ—¥å¿—æ¨¡å¼:")
    print('uv run python main.py "video.mp4" --mode full -l en -s è‹±æ–‡ -t ä¸­æ–‡ --verbose')
    
    print("\nğŸ“ å®‰é™æ¨¡å¼:")
    print('uv run python main.py "video.mp4" --mode full -l en -s è‹±æ–‡ -t ä¸­æ–‡ --quiet')
    
    print("\nğŸ“ è¦†ç›–ç¯å¢ƒå˜é‡:")
    print('uv run python main.py "srt_file.srt" --mode translate --api-key your_key --base-url https://your.proxy.com/v1 --llm-model gpt-4')
    
    print("\nğŸ“ æ‰¹é‡å¤„ç†è„šæœ¬:")
    batch_script = '''
# æ‰¹é‡å¤„ç†å¤šä¸ªéŸ³é¢‘æ–‡ä»¶
for file in *.mp4; do
    echo "å¤„ç†æ–‡ä»¶: $file"
    uv run python main.py "$file" --mode full -l en -s è‹±æ–‡ -t ä¸­æ–‡ --auto-config
done
'''
    print(batch_script)

def example_environment_setup():
    """ç¯å¢ƒé…ç½®ç¤ºä¾‹"""
    print("\n" + "=" * 60)
    print("ğŸ”§ ç¤ºä¾‹6: ç¯å¢ƒé…ç½®")
    print("=" * 60)
    
    print("ğŸ“ ä»£ç†æä¾›å•†é…ç½® (Linux/macOS):")
    env_linux = '''
export OPENAI_API_KEY=your_api_key
export MODEL_BASE_URL=https://your.proxy.com/v1
export MODEL_NAME=gpt-4o-mini
'''
    print(env_linux)
    
    print("ğŸ“ ä»£ç†æä¾›å•†é…ç½® (Windows PowerShell):")
    env_windows = '''
$env:OPENAI_API_KEY="your_api_key"
$env:MODEL_BASE_URL="https://your.proxy.com/v1"
$env:MODEL_NAME="gpt-4o-mini"
'''
    print(env_windows)
    
    print("ğŸ“ éªŒè¯é…ç½®:")
    print('uv run python main.py "test.mp4" --dry-run')

def example_troubleshooting():
    """æ•…éšœæ’é™¤ç¤ºä¾‹"""
    print("\n" + "=" * 60)
    print("ğŸ” ç¤ºä¾‹7: æ•…éšœæ’é™¤")
    print("=" * 60)
    
    print("ğŸ“ æ£€æŸ¥ä¾èµ–:")
    print('uv add faster-whisper soundfile psutil langgraph langchain-openai')
    
    print("\nğŸ“ å†…å­˜ä¸è¶³æ—¶ä½¿ç”¨tinyæ¨¡å‹:")
    print('uv run python main.py "video.mp4" --mode transcribe -m tiny --compute-type int8 --cpu-threads 2')
    
    print("\nğŸ“ ç¿»è¯‘å¤±è´¥æ—¶å‡å°‘æ‰¹é‡å¤§å°:")
    print('uv run python main.py "subtitle.srt" --mode translate -s è‹±æ–‡ -t ä¸­æ–‡ -b 2')
    
    print("\nğŸ“ ç½‘ç»œé—®é¢˜æ—¶çš„é‡è¯•:")
    print('# å¦‚æœç¿»è¯‘ä¸­æ–­ï¼Œå¯ä»¥å•ç‹¬è¿è¡Œç¿»è¯‘éƒ¨åˆ†')
    print('uv run python main.py "existing_subtitle.srt" --mode translate -s è‹±æ–‡ -t ä¸­æ–‡')

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¬ main.py ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 60)
    
    while True:
        print("\nğŸ”§ é€‰æ‹©ç¤ºä¾‹:")
        print("0. ç¯å¢ƒæ£€æŸ¥")
        print("1. ç©ºè¿è¡Œæ¨¡å¼ (éªŒè¯é…ç½®)")
        print("2. ä»…éŸ³é¢‘è½¬å½•")
        print("3. ä»…å­—å¹•ç¿»è¯‘")  
        print("4. å®Œæ•´å·¥ä½œæµ")
        print("5. é«˜çº§ç”¨æ³•")
        print("6. ç¯å¢ƒé…ç½®")
        print("7. æ•…éšœæ’é™¤")
        print("q. é€€å‡º")
        
        choice = input("\nè¯·é€‰æ‹© (0-7, q): ").strip()
        
        if choice == 'q':
            print("ğŸ‘‹ å†è§!")
            break
        elif choice == '0':
            check_environment()
        elif choice == '1':
            example_dry_run()
        elif choice == '2':
            example_transcribe_only()
        elif choice == '3':
            example_translate_only()
        elif choice == '4':
            example_full_workflow()
        elif choice == '5':
            example_advanced_usage()
        elif choice == '6':
            example_environment_setup()
        elif choice == '7':
            example_troubleshooting()
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
        
        input("\næŒ‰å›è½¦é”®ç»§ç»­...")

if __name__ == "__main__":
    main() 