1
00:00:00,000 --> 00:00:05,160
Welcome to our new Line Chain Academy course, Building Amid Agents with Line Graph.
欢迎来到我们的Line Chain学院新课程：使用Line Graph构建多智能体。

2
00:00:05,160 --> 00:00:11,160
Chat is a familiar user interaction pattern for agents, where user request something of an agent,
聊天是智能体常见的一种用户交互模式，用户向智能体提出请求，

3
00:00:11,160 --> 00:00:16,190
an agent can call various tools, and respond to the user with an output.
智能体可以调用各种工具，并向用户输出响应。

4
00:00:16,190 --> 00:00:21,289
But there are a lot of tasks for which chat isn't quite appropriate.
但有很多任务并不适合用聊天模式。

5
00:00:21,289 --> 00:00:26,289
As an example, many users don't want to actually tell an agent do something.
例如，许多用户并不想真正告诉智能体该做什么。

6
00:00:26,289 --> 00:00:32,420
They want an agent to listen passively to certain events and respond to them automatically.
他们希望代理能被动监听特定事件，并自动响应。

7
00:00:32,420 --> 00:00:37,420
Many times we don't want agents to only handle one request at a time.
很多时候，我们不希望代理一次只处理一个请求。

8
00:00:37,420 --> 00:00:40,420
We may want agents to handle many events concurrently.
我们可能希望代理能同时处理多个事件。

9
00:00:40,420 --> 00:00:44,420
Sometimes we want agents to do work in the background for us,
有时我们希望代理能在后台为我们工作，

10
00:00:44,420 --> 00:00:49,420
and only notify us at specific points, like when the work has been done,
只在特定时刻通知我们，比如工作完成时，

11
00:00:49,420 --> 00:00:55,579
when they need clarification on something, or when they want to notify us about something.
当他们需要澄清某事，或想通知我们某事时。

12
00:00:55,579 --> 00:01:01,609
And finally, with chat, you typically want the agent to work quickly.
最后，对于聊天，你通常希望客服能快速处理。

13
00:01:01,609 --> 00:01:06,829
But if agents are doing work in the background, it can take much longer.
但如果客服在后台工作，可能需要更长时间。

14
00:01:06,829 --> 00:01:11,829
A user isn't waiting around. They're only notified by the agent when appropriate.
用户不用一直等着。客服只会在适当的时候通知他们。

15
00:01:11,829 --> 00:01:16,120
So this collection of attributes is what we call ambient agents.
所以这些属性的集合，我们称之为“环境代理”。

16
00:01:16,120 --> 00:01:21,150
Now in this course, we're going to build an ambient agent that can handle email,
在这门课中，我们将构建一个环境智能体，来处理邮件

17
00:01:21,150 --> 00:01:26,150
which is a great example of the kind of task you may want agents like this to take on.
这类任务很适合让智能体来完成

18
00:01:26,150 --> 00:01:31,500
It's going to build an agent that can effectively manage your email inbox.
它能有效地管理你的收件箱

19
00:01:31,500 --> 00:01:38,540
It will ingest incoming emails and perform actions like draft responses or schedule meetings.
接收邮件，并执行起草回复或安排会议等操作

20
00:01:38,540 --> 00:01:45,659
Now because these are sensitive tasks, we're going to show how to use human loop to approve certain agent actions.
由于这些任务比较敏感，我们将展示如何使用人工审核来批准某些智能体操作

21
00:01:46,659 --> 00:01:52,659
And importantly, we're also going to introduce memory so that the agent learns from our feedback over time.
重要的是，我们还会引入记忆功能，让智能体能从我们的反馈中不断学习。

22
00:01:52,659 --> 00:01:57,019
And by the end of this course, you're going to understand all these components
学完这门课，你就能理解所有这些组件

23
00:01:57,019 --> 00:02:01,019
and how they can be used generally to build agents, not just that handle email,
以及它们如何被普遍用于构建智能体，不只是处理邮件的智能体，

24
00:02:01,019 --> 00:02:04,459
but they can handle many different types of tasks.
还能处理许多不同类型的任务。

25
00:02:04,459 --> 00:02:06,459
So how can we actually build this?
那么，我们到底该如何构建它呢？

26
00:02:06,459 --> 00:02:09,659
Let's take the simplest possible email system.
让我们用最简单的邮件系统举例。

27
00:02:09,659 --> 00:02:14,659
For every incoming email, the assistant produces a response email.
每收到一封邮件，助手就会生成一封回复邮件。

28
00:02:14,659 --> 00:02:18,689
Now the assistant can send that response using tool calling,
助手可以通过调用工具发送回复，

29
00:02:18,689 --> 00:02:20,689
which I'll talk about briefly in a minute.
我稍后会简单介绍。

30
00:02:20,689 --> 00:02:24,689
And if you think about the system in terms of agency versus predictability,
如果你从“自主性”和“可预测性”的角度来思考这个系统，

31
00:02:24,689 --> 00:02:29,689
where agency is the ability for the system to make different decisions and predictability is,
代理能力是指系统做出不同决策的能力，可预测性则是指

32
00:02:29,689 --> 00:02:32,689
simply the predictability decisions the system makes,
系统做出决策的可预测性。

33
00:02:32,689 --> 00:02:35,689
this would be low agency but high predictability.
这就是低代理能力，但高可预测性。

34
00:02:35,689 --> 00:02:41,689
It will always call a tool to send off an email for every incoming email that it receives.
它会为收到的每封邮件调用工具发送邮件。

35
00:02:41,689 --> 00:02:46,689
The central concept underpinning this system and agents more broadly is tool calling.
支撑这个系统乃至更广泛的代理的核心概念是工具调用。

36
00:02:46,689 --> 00:02:49,689
Let's imagine we had an email API.
假设我们有一个邮件API。

37
00:02:49,689 --> 00:02:51,689
This could be the Gmail API as an example.
比如Gmail API。

38
00:02:51,689 --> 00:02:56,689
We can turn that into a tool and bind it to an LLM.
我们可以把它变成一个工具，然后绑定到一个大型语言模型（LLM）上。

39
00:02:56,689 --> 00:03:04,819
When we do that binding process, the LLM understands the arguments necessary to actually call that tool.
在绑定过程中，LLM会理解调用这个工具所需的参数。

40
00:03:04,819 --> 00:03:06,819
So when it receives a request,
所以当它收到请求时，

41
00:03:06,819 --> 00:03:12,039
it reasons about the request and can make a decision to call the tool,
它会分析请求，然后决定是否调用工具，

42
00:03:12,039 --> 00:03:15,039
but importantly produces a structured output,
但重要的是，它会生成一个结构化的输出，

43
00:03:15,039 --> 00:03:19,039
which contains the arguments that the tool actually needs.
其中包含工具实际需要的参数。

44
00:03:19,039 --> 00:03:25,039
Independently, then, the tool can be executed with those arguments in order to,
之后，工具就可以独立地用这些参数来执行，

45
00:03:25,039 --> 00:03:27,039
in this case, send off an email.
在这个例子中，就是发送一封邮件。

46
00:03:27,039 --> 00:03:33,039
Now it's important to note that a simple system to always call an email tool is pretty limited.
值得注意的是，一个简单的系统，如果总是调用邮件工具，会很受限。

47
00:03:33,039 --> 00:03:35,389
What if we don't want to respond?
如果我们不想回复呢？

48
00:03:36,550 --> 00:03:42,550
So there's many different ways people have found to effectively lay out workflows.
所以人们找到了许多有效的方法来规划工作流程。

49
00:03:42,550 --> 00:03:47,550
This is just LLM calls within predefined code paths.
这只是预定义代码路径中的LLM调用。

50
00:03:47,550 --> 00:03:50,650
That can instrument specific logic.
它可以实现特定的逻辑。

51
00:03:50,650 --> 00:03:59,000
Here's an example where we're put a router prior to that send email tool call.
举个例子，我们在调用发送邮件工具前，

52
00:03:59,000 --> 00:04:04,060
This router then makes decision about whether or not we're going to send the email.
先放了一个路由器，它会决定是否发送邮件。

53
00:04:04,060 --> 00:04:11,060
If we make a decision to send, we'll then go ahead and proceed to what we just talked about,
如果决定发送，我们就会继续执行刚才说的，

54
00:04:11,060 --> 00:04:15,319
an LLM with access to an email tool and the email sent.
让大语言模型访问邮件工具，然后发送邮件。

55
00:04:15,319 --> 00:04:19,379
Now if you think about this system, we've bump up the agency a little bit.
思考一下这个系统，我们稍微提升了自主性。

56
00:04:19,379 --> 00:04:21,379
Now it has the ability to make a decision.
现在它能做决定了。

57
00:04:21,379 --> 00:04:24,959
It can decide whether or not to respond.
它能决定是否回应。

58
00:04:24,959 --> 00:04:26,959
And in turn, it's a little bit less predictable.
反过来，它就没那么可预测了。

59
00:04:26,959 --> 00:04:32,180
We don't quite know what I'll decide given it an incoming email.
我们不确定它收到邮件后会怎么决定。

60
00:04:32,180 --> 00:04:35,220
Now let's push this even further.
现在，我们再进一步。

61
00:04:35,220 --> 00:04:39,220
Imagine we took that LLM and instead of giving it a single tool right email,
想象一下，我们用这个大型语言模型，不是只给它一个工具，比如写邮件，

62
00:04:39,220 --> 00:04:42,220
we give it a collection of different tools.
而是给它一系列不同的工具。

63
00:04:42,220 --> 00:04:49,339
And every time it called a tool, we just returned the output of that tool call back to the LLM.
每次它调用一个工具，我们都把工具调用的输出返回给大型语言模型。

64
00:04:49,339 --> 00:04:54,339
We'll let the LLM think about what was performed and decide what to do next.
我们让大型语言模型思考执行了什么，然后决定下一步做什么。

65
00:04:54,339 --> 00:04:58,569
We let that proceed in a loop until some termination condition.
我们让这个过程循环进行，直到达到某个终止条件。

66
00:04:58,569 --> 00:05:00,569
This very simply is an agent.
这很简单，就是一个智能体。

67
00:05:00,569 --> 00:05:05,569
And as noted, the agency is quite a bit higher than the other two.
如前所述，它的自主性比另外两个高很多。

68
00:05:05,569 --> 00:05:10,790
And one way to visualize that is with the initial system,
有个方法可以直观地理解，

69
00:05:10,790 --> 00:05:17,019
for every incoming email, it made a single decision to write a response and send it.
最初的系统，每收到一封邮件，它就做一个决定：写回复并发送。

70
00:05:17,019 --> 00:05:25,240
The agent in contrast can choose any sequence of tool calls given the tools it has access to.
而智能体则不同，它可以选择任何工具调用序列，只要它能访问这些工具。

71
00:05:25,240 --> 00:05:28,240
So in this case, let's say it had access to three tools.
假设它能用三个工具。

72
00:05:28,240 --> 00:05:30,240
Check calendar schedule meeting, write an email.
查看日历、安排会议、写邮件。

73
00:05:30,240 --> 00:05:32,339
It can pick any sequence.
它可以根据邮件输入，

74
00:05:32,339 --> 00:05:34,339
It wants based upon the email input.
选择任意顺序。

75
00:05:34,339 --> 00:05:39,339
Now a very important question is how to think about workflows or his agents.
那么，如何思考工作流或代理呢？

76
00:05:39,339 --> 00:05:44,689
Typically, a good statistic is if you can easily draw the control flow on a whiteboard
通常，一个好的统计数据是，你可以在白板上轻松绘制控制流

77
00:05:44,689 --> 00:05:48,689
and it's very easy to numerate in advanced workflows appropriate,
而且很容易在高级工作流中进行枚举，

78
00:05:48,689 --> 00:05:54,100
and often is lower latency and cost than an agent.
而且通常比代理的延迟和成本更低。

79
00:05:54,100 --> 00:05:57,100
But if you actually need more flexible decision making,
但如果你确实需要更灵活的决策，

80
00:05:57,100 --> 00:06:01,230
and you can't quite know until runtime,
而且在运行时之前无法确定，

81
00:06:01,230 --> 00:06:04,420
or in this case, until you receive an email,
或者像这种情况，直到你收到邮件，

82
00:06:04,420 --> 00:06:07,420
how you want to respond in terms of tool calls,
你想如何用工具调用来回应，

83
00:06:07,420 --> 00:06:09,420
then an agent is more appropriate.
那么代理就更合适。

84
00:06:09,420 --> 00:06:15,810
And it's okay to trade off greater reasoning for higher latency and potentially higher cost.
牺牲推理能力来换取更高的延迟和潜在成本是可以接受的。

85
00:06:15,810 --> 00:06:20,810
Now, line graph comes in because it's a framework of low-level components
现在，Line Graph之所以出现，是因为它是一个由低级组件组成的框架，

86
00:06:20,810 --> 00:06:26,000
that lets you flexibly build and combine workflows and agents.
让你灵活地构建和组合工作流及代理。

87
00:06:26,000 --> 00:06:31,129
Line graph is composed of nodes and edges where nodes are just units of work.
线图由节点和边组成，节点就是工作单元。

88
00:06:31,129 --> 00:06:37,259
There's Python functions or TypeScript code that you control explicitly.
它们是你可以明确控制的Python函数或TypeScript代码。

89
00:06:37,259 --> 00:06:40,290
So you'll just write those functions as you'll see shortly.
所以你只需编写这些函数，稍后你就会看到。

90
00:06:40,290 --> 00:06:44,579
And everything happens with the node you have complete control over.
一切都发生在节点上，你拥有完全的控制权。

91
00:06:44,579 --> 00:06:47,639
Now, edges are just transitions between nodes,
边是节点之间的转换，

92
00:06:47,639 --> 00:06:51,639
which are going to lay out in advance as you build your workflow arrangement.
你可以在构建工作流编排时提前布局。

93
00:06:51,639 --> 00:06:54,639
This will dictate the control flow of the application.
这将决定应用程序的控制流。

94
00:06:54,639 --> 00:07:01,639
Now, one benefit of line graph is that because it uses very low-level components,
线图的一个好处是，因为它使用非常底层的组件，

95
00:07:01,639 --> 00:07:08,019
just simply nodes and edges, you can build many different workflows as well as agents very easily.
仅仅是节点和边，你可以非常容易地构建许多不同的工作流和代理。

96
00:07:08,019 --> 00:07:12,410
It allows you to kind of move to where you want to sit along this curve.
它能让你沿着这条曲线

97
00:07:12,410 --> 00:07:15,410
You can build systems that are strictly agents.
移动到你想坐的位置。

98
00:07:15,410 --> 00:07:17,410
You can build workflows.
你可以构建纯粹的代理系统。

99
00:07:17,410 --> 00:07:20,410
You can combine agents and workflows together.
你可以构建工作流。

100
00:07:20,410 --> 00:07:24,439
Now, one of the things we built into line graph that we found to be very important,
你可以将代理和工作流结合起来。

101
00:07:24,439 --> 00:07:27,439
in particular, as we'll see here, building an ambient agent,
尤其是，我们将会看到，构建一个环境智能体，

102
00:07:27,439 --> 00:07:33,500
is a persistence layer that enables human and loop and long-term memory.
是一个持久层，它能让人类参与到循环中，并拥有长期记忆。

103
00:07:33,500 --> 00:07:40,660
As we'll see, it's important in many cases that agents can pause in a way human feedback.
我们会看到，在许多情况下，智能体能暂停以获取人类反馈，这很重要。

104
00:07:40,660 --> 00:07:43,660
And that's what the persistence layer affords this.
这就是持久层所能提供的。

105
00:07:43,660 --> 00:07:48,759
Not only that, it also gives us long-term memory.
不仅如此，它还赋予我们长期记忆。

106
00:07:48,759 --> 00:07:52,759
The central idea behind persistence is that you have check pointing.
持久化的核心思想是检查点。

107
00:07:52,759 --> 00:07:56,759
So, as you'll see, when you lay out your graph as a set of nodes,
稍后你就会看到，当你把图表布置成一组节点时，

108
00:07:56,759 --> 00:08:01,759
the check pointer will save the state of the application.
检查点会保存应用程序的状态。

109
00:08:01,759 --> 00:08:06,759
And if we pause it, that state is available for us to resume from later.
如果我们暂停它，这个状态就可以供我们以后恢复。

110
00:08:06,759 --> 00:08:11,430
Line graph also comes built with an interactive development environment,
线图还内置了交互式开发环境，

111
00:08:11,430 --> 00:08:15,430
Line Graph Studio, which you're going to see extensively throughout this course.
Line Graph Studio，在本课程中你会大量看到它。

112
00:08:15,430 --> 00:08:18,430
And it provides an easy on-roam to deployment.
它提供了一种简单的部署方式。

113
00:08:18,430 --> 00:08:22,430
And you'll see that we can very easily go from code running in a notebook
你会看到，我们可以非常轻松地将笔记本中运行的代码

114
00:08:22,430 --> 00:08:24,430
to a deployable application.
转换为可部署的应用程序。

115
00:08:24,430 --> 00:08:26,980
Before I actually build in our agent,
在我实际构建我们的代理之前，

116
00:08:26,980 --> 00:08:30,980
I want to make sure we understand the fundamentals of Line Graph very clearly
我想确保大家对“线图”的基础知识有清晰的理解，

117
00:08:30,980 --> 00:08:33,980
and how it works with Langshin and Langsmith.
以及它如何与LangChain和LangSmith协同工作。

118
00:08:34,980 --> 00:08:37,980
Here's a general schematic where you can see the three together.
这是三者结合的示意图。

119
00:08:37,980 --> 00:08:43,200
Langshin provides many integrations that we'll be using, particularly chat models,
LangChain提供了许多我们将用到的集成，特别是聊天模型，

120
00:08:43,200 --> 00:08:49,679
and some very useful methods for binding tools or structured outputs.
以及一些非常有用的方法，用于绑定工具或结构化输出。

121
00:08:49,679 --> 00:08:52,679
Line Graph will be using for agent orchestration.
线性图将用于智能体编排。

122
00:08:52,679 --> 00:08:58,870
Langsmith remusing for observability, like tracing, as well as evaluation.
Langsmith 用于可观测性，比如追踪和评估。

123
00:08:58,870 --> 00:09:02,870
And as you'll see, these three all play really nicely together,
稍后你会看到，这三者配合得很好，

124
00:09:02,870 --> 00:09:04,870
but this is how they're related.
它们就是这样关联的。

125
00:09:04,870 --> 00:09:08,289
Now, chat models are the foundation of LLM applications.
现在，聊天模型是大型语言模型应用的基础。

126
00:09:08,289 --> 00:09:11,480
They're typically accessed through a chat interface,
它们通常通过聊天界面访问，

127
00:09:11,480 --> 00:09:13,480
which takes the list of messages input,
聊天界面接收消息列表作为输入，

128
00:09:13,480 --> 00:09:15,480
the returns and messages output,
返回消息输出，

129
00:09:15,480 --> 00:09:20,669
and Langshin's standard interface for chat models called init chat model,
以及LangChain用于聊天模型的标准接口，名为“init chat model”，

130
00:09:20,669 --> 00:09:25,740
where you can just simply pass the name of your provider and model,
你只需传入提供商和模型的名称即可，

131
00:09:25,740 --> 00:09:29,740
as well as any parameters that you want to use.
以及任何你想用的参数。

132
00:09:29,740 --> 00:09:33,250
Now, Langshin has some universal methods
LangChain有一些通用方法

133
00:09:33,250 --> 00:09:36,629
for accessing chat models.
用于访问聊天模型。

134
00:09:36,629 --> 00:09:40,629
Invoke just passes a single input to the chat model and returns an output.
Invoke只是将单个输入传递给聊天模型并返回一个输出。

135
00:09:40,629 --> 00:09:44,950
In this case, we can just pass a string and under the hood,
在这种情况下，我们只需传递一个字符串，在底层，

136
00:09:44,950 --> 00:09:47,950
it's converted into a chat message and sent in for us.
它会被转换成聊天消息，然后发送给我们。

137
00:09:47,950 --> 00:09:51,269
We can see we get a message out.
我们可以看到我们收到了一条消息。

138
00:09:51,269 --> 00:09:55,370
Now, here's the message, and you can see it has this content,
这就是那条消息，你可以看到它有这些内容，

139
00:09:55,370 --> 00:09:57,370
as well as response metadata.
还有响应元数据。

140
00:09:57,370 --> 00:10:00,370
Now, tools, as mentioned previously,
之前提到过，工具

141
00:10:00,370 --> 00:10:03,370
are utilities that can be called by chat models.
是聊天模型可以调用的实用程序。

142
00:10:03,370 --> 00:10:06,820
We can very easily create tools in Langshin
我们可以用LangChain轻松创建工具

143
00:10:06,820 --> 00:10:11,820
from Python functions as an example using this tool decorator.
比如用Python函数，使用这个工具装饰器。

144
00:10:11,820 --> 00:10:16,230
Now, this function is a tool,
现在，这个函数是一个工具，

145
00:10:16,230 --> 00:10:20,230
and when we do this, the tool arguments, as well as description,
当我们这样做时，工具参数以及描述，

146
00:10:20,230 --> 00:10:22,230
are automatically inferred.
自动推断。

147
00:10:22,230 --> 00:10:25,299
These are things that are going to be passed to the model,
这些参数会传递给模型，

148
00:10:25,299 --> 00:10:29,299
so the model knows what this particular tool is expecting.
让模型知道这个工具需要什么。

149
00:10:29,299 --> 00:10:32,620
Now, one thing that's very nice is that
另外，LangChain 的

150
00:10:32,620 --> 00:10:35,620
the chat model interface in Langshin
聊天模型接口

151
00:10:35,620 --> 00:10:38,620
provides some common methods for working with tools.
提供了一些使用工具的常用方法。

152
00:10:38,620 --> 00:10:41,620
In particular, this bind tools method,
特别是这个绑定工具的方法，

153
00:10:41,620 --> 00:10:48,960
we can simply pass a list of tools in some useful parameters.
我们只需传入一个工具列表和一些有用的参数。

154
00:10:48,960 --> 00:10:51,960
So this tool choice parameter means that the model is enforced
所以这个“工具选择”参数意味着模型被强制要求

155
00:10:51,960 --> 00:10:54,960
to call any available tool that it has.
调用它拥有的任何可用工具。

156
00:10:54,960 --> 00:10:58,889
So it will always have to call a tool.
所以它总得调用工具。

157
00:10:58,889 --> 00:11:03,889
Parallel tool calls simply enforces the model calls a single tool at a time.
并行工具调用只是强制模型一次调用一个工具。

158
00:11:03,889 --> 00:11:06,889
Sometimes models can actually make multiple tool calls at once,
有时模型可以一次调用多个工具，

159
00:11:06,889 --> 00:11:08,889
and we can control that.
我们可以控制它。

160
00:11:08,889 --> 00:11:12,340
So we define our model with tools.
所以我们用工具定义模型。

161
00:11:12,340 --> 00:11:14,340
We invoke it just like before.
我们像之前一样调用它。

162
00:11:14,340 --> 00:11:20,370
In this case, we invoke it with a message that's related to the tool it has,
在这种情况下，我们用一条与它拥有的工具相关的消息来调用它，

163
00:11:20,370 --> 00:11:25,620
and we can see the tool call itself has the arguments needed
我们可以看到工具调用本身具有所需的参数

164
00:11:25,620 --> 00:11:30,909
to actually run the tool to subject content.
来实际运行该工具以提交内容。

165
00:11:30,909 --> 00:11:35,909
We can pass those args directly to our tool right email and just run it,
我们可以将这些参数直接传递给我们的工具，然后运行它，

166
00:11:35,909 --> 00:11:38,909
and then we can see our tool was executed.
这样就能看到工具已执行。

167
00:11:38,909 --> 00:11:41,909
So this is a very important concept to understand.
这是个非常重要的概念。

168
00:11:41,909 --> 00:11:44,070
You can bind tools to LLMs.
你可以将工具绑定到大模型。

169
00:11:44,070 --> 00:11:46,070
LLMs can call tools.
大模型可以调用工具。

170
00:11:46,070 --> 00:11:50,070
Calling tools simply means that LLMs produce a structured output of arguments
调用工具，就是大模型会生成结构化的参数输出。

171
00:11:50,070 --> 00:11:52,070
necessary to actually run the tool,
必须实际运行这个工具，

172
00:11:52,070 --> 00:11:55,070
and then the tool can be independently run.
然后这个工具就可以独立运行。

173
00:11:55,070 --> 00:11:58,070
This is really the foundational component for building agents.
这确实是构建智能体的基础组件。

174
00:11:58,070 --> 00:12:03,070
And what we see above illustrates this simple flow that we saw before.
我们在上面看到的，说明了我们之前看到的这个简单流程。

175
00:12:03,070 --> 00:12:07,649
We bind a single send email tool to an LLMs,
我们将一个发送邮件工具绑定到大语言模型上，

176
00:12:07,649 --> 00:12:12,649
and enforce it to call that tool when responding to incoming emails or requests.
并强制它在回复邮件或请求时，调用该工具。

177
00:12:12,649 --> 00:12:17,779
Now as discussed, workflows and agents really extend from this.
正如之前讨论的，工作流和代理都由此延伸。

178
00:12:17,779 --> 00:12:23,779
In case of workflows, we can embed LLMs calls in predefined code paths.
对于工作流，我们可以在预定义的代码路径中嵌入大型语言模型调用。

179
00:12:23,779 --> 00:12:28,779
As we see here, with a router prior to our LLMs calls our email tool.
正如我们所见，在大型语言模型调用我们的邮件工具之前，有一个路由器。

180
00:12:28,779 --> 00:12:31,779
Agents just extend this a bit further,
代理只是在此基础上更进一步，

181
00:12:31,779 --> 00:12:35,779
allowing LLMs to sequentially call tools in a loop.
让大型语言模型能循环、按序调用工具。

182
00:12:35,779 --> 00:12:39,779
Now, land graph sits underneath any workflow or agent,
现在，LandGraph 成为所有工作流和代理的基础，

183
00:12:39,779 --> 00:12:44,779
and it provides a few specific benefits we're going to walk through now in code in some simple examples.
它提供了一些特定的优势，我们现在将通过代码和一些简单示例来演示。

184
00:12:44,779 --> 00:12:46,779
The first benefit is control.
第一个优势是控制。

185
00:12:46,779 --> 00:12:50,970
It makes it very easy to define or combine ages and workflows.
它让定义或组合代理和工作流变得非常容易。

186
00:12:50,970 --> 00:12:52,970
The second benefit is persistence.
第二个好处是持久性。

187
00:12:52,970 --> 00:12:55,970
It provides a way to persist the state of our graph,
它提供了一种持久保存图状态的方法，

188
00:12:55,970 --> 00:12:59,970
which enables both memory and human loop, which we're going to see.
这使得内存和人工循环都成为可能，我们将会看到。

189
00:12:59,970 --> 00:13:04,029
And it provides an easy on-ramp for testing debugging and deploying applications.
它为测试、调试和部署应用程序提供了一个简单的入门途径。

190
00:13:04,029 --> 00:13:06,029
Now let's talk about control first.
现在我们先谈谈控制。

191
00:13:06,029 --> 00:13:09,029
Land graph lets you define your applications a graph,
LangGraph能让你把应用定义成图，

192
00:13:09,029 --> 00:13:13,029
with three important things that you just specify.
你只需指定三件重要的事。

193
00:13:13,029 --> 00:13:17,059
The state or the information you want to track over the course of the application,
状态，也就是你想在应用中追踪的信息，

194
00:13:18,059 --> 00:13:22,059
nodes, how do you want to update the state over the course of the application,
节点，你希望如何在应用中更新状态，

195
00:13:22,059 --> 00:13:26,509
and edges, how do you want to connect the nodes together.
以及边，你希望如何连接这些节点。

196
00:13:26,509 --> 00:13:29,509
Now we use the state graph class to initialize a line graph graph,
现在我们用状态图类初始化一个线图，

197
00:13:29,509 --> 00:13:32,769
and we just pass in a state object.
然后传入一个状态对象。

198
00:13:32,769 --> 00:13:37,769
Now the state object is basically the schema for the information we want to track over the course of the application.
状态对象基本上就是我们想在应用中跟踪的信息的模式。

199
00:13:37,769 --> 00:13:41,500
Now there's a few options for defining your schema.
定义模式有几种选择。

200
00:13:41,500 --> 00:13:45,889
As an example, type dicts are fast,
举个例子，类型字典很快，

201
00:13:45,889 --> 00:13:49,019
but they don't support default values.
但它们不支持默认值。

202
00:13:49,019 --> 00:13:54,750
Data classes are actually quite nice because they do support defaults.
数据类其实很好用，因为它们支持默认值。

203
00:13:54,750 --> 00:14:00,039
Padantic is a bit slower, but allows for type validation.
Pydantic 会慢一点，但支持类型验证。

204
00:14:00,039 --> 00:14:04,620
So you can choose the schema that's appropriate for your application.
所以你可以选择适合你应用的模式。

205
00:14:04,620 --> 00:14:06,620
In this simple case, let's just use the type dict.
这个简单例子，我们用类型字典就好。

206
00:14:06,620 --> 00:14:09,620
You can see I'm defining my state schema here.
大家可以看到，我在这里定义了状态模式。

207
00:14:09,620 --> 00:14:14,129
It just has two keys, request, and email both strings.
它只有两个键，请求和电子邮件，都是字符串。

208
00:14:14,129 --> 00:14:18,289
I then initialize my state graph with my schema.
然后我用模式初始化我的状态图。

209
00:14:18,289 --> 00:14:21,860
Now let's take what we did previously.
现在让我们看看之前做的。

210
00:14:21,860 --> 00:14:24,860
We call our model of tools with an input request.
我们用输入请求调用工具模型。

211
00:14:24,860 --> 00:14:26,860
We get the arguments, and we call it tool.
我们获取参数，然后称之为工具。

212
00:14:26,860 --> 00:14:29,860
We can put that all in a node in our graph,
我们可以把它放到图中的一个节点里，

213
00:14:29,860 --> 00:14:32,860
and you'll see two interesting things about this.
你会发现它有两点很有趣。

214
00:14:32,860 --> 00:14:36,860
One, the node takes in our state object.
第一，这个节点接收我们的状态对象。

215
00:14:36,860 --> 00:14:39,860
Remember, we define that above a natural sedictionary.
记住，我们之前把它定义为一个自然字典。

216
00:14:39,860 --> 00:14:43,860
From the dictionary, we can extract any keys we want and utilize them.
我们可以从字典中提取任何键值并使用。

217
00:14:43,860 --> 00:14:46,990
Now the second thing is, it returns a dict.
第二点是，它会返回一个字典。

218
00:14:46,990 --> 00:14:51,470
This return is basically updating our state.
这个返回基本上是在更新我们的状态。

219
00:14:51,470 --> 00:14:55,470
Now by default, when we return from a node,
默认情况下，当我们从一个节点返回时，

220
00:14:55,470 --> 00:14:59,659
it overwrites that particular key in our state,
它会覆盖我们状态中的特定键值，

221
00:14:59,659 --> 00:15:02,659
but when we define our state object,
但当我们定义状态对象时，

222
00:15:02,659 --> 00:15:05,659
there are ways to customize it to do different things,
有些方法可以自定义它，让它做不同的事情，

223
00:15:05,659 --> 00:15:09,080
like appending, and we'll talk about that shortly.
比如追加，我们稍后会讲到。

224
00:15:09,080 --> 00:15:14,659
In this simple case, though, we're going to call our model of tools.
不过，在这个简单的例子中，我们将把工具模型称为

225
00:15:14,659 --> 00:15:16,659
It's going to produce a tool call.
它会生成一个工具调用。

226
00:15:16,659 --> 00:15:19,659
We then pass those arguments to our right email tool.
然后我们把这些参数传给邮件工具。

227
00:15:19,659 --> 00:15:26,909
We can email out, and we'll update or overwrite our state key email with that output.
我们可以发送邮件，然后用输出内容更新或覆盖状态键。

228
00:15:26,909 --> 00:15:33,980
Now we can specify the control flow by adding nodes and edges to our graph.
现在，我们可以通过向图中添加节点和边来指定控制流。

229
00:15:33,980 --> 00:15:37,039
We'll add our single node, right email node,
我们将添加单个节点，即邮件节点，

230
00:15:37,039 --> 00:15:42,580
and two edges to start, go to that node,
并从两个边开始，转到该节点，

231
00:15:42,580 --> 00:15:47,649
from that node, go to end, and finally, we compile it.
从那个节点开始，一直到结束，最后我们编译它。

232
00:15:47,649 --> 00:15:51,649
When we've done these things, we can very easily then run our graph
完成这些后，我们就能很轻松地运行图表了

233
00:15:51,649 --> 00:15:56,649
just by calling invoke, and we can pass an initial value to our state.
只需调用invoke，就能给状态传入初始值。

234
00:15:56,649 --> 00:16:01,649
In this case, we'll initialize our graph with request,
这里，我们用请求初始化图表，

235
00:16:01,649 --> 00:16:08,970
and we see the output of the tool call is written to email in our state.
然后我们看到工具调用的输出被写入了状态中的邮件。

236
00:16:08,970 --> 00:16:11,970
The state dict is just returned.
状态字典已返回。

237
00:16:11,970 --> 00:16:14,320
We run our graph.
我们运行图。

238
00:16:14,320 --> 00:16:19,320
Now in the above case, we very simply used edges to start,
在上面这个例子中，我们简单地用边来开始，

239
00:16:19,320 --> 00:16:23,450
go to our single node, and then go from our single node to end.
到达我们的单节点，然后从单节点到结束。

240
00:16:23,450 --> 00:16:27,450
We can also do conditional routing using conditional edges.
我们也可以使用条件边进行条件路由。

241
00:16:27,450 --> 00:16:30,019
Let me show an example of that.
我来举个例子。

242
00:16:30,019 --> 00:16:35,019
Now let's split our graph up into two different nodes, call the LLM,
现在我们把图分成两个节点，调用大型语言模型，

243
00:16:35,019 --> 00:16:37,309
and run our tool.
然后运行工具。

244
00:16:37,309 --> 00:16:40,409
Now we can add a conditional edge.
现在我们可以添加一个条件边。

245
00:16:40,409 --> 00:16:45,409
It looks to see if a tool call was made by call alone,
它会查看是否通过单独调用进行了工具调用，

246
00:16:45,409 --> 00:16:49,789
and if so, run the tool if not to send.
如果是，就运行工具，否则不发送。

247
00:16:49,789 --> 00:16:52,789
This is a very common thing that we do when we build agents.
这是我们构建智能体时很常见的一种做法。

248
00:16:52,789 --> 00:16:56,950
We use conditional routing as a termination condition.
我们使用条件路由作为终止条件。

249
00:16:56,950 --> 00:16:59,950
If the agent is making a tool call, we run it.
如果智能体正在调用工具，我们就运行它。

250
00:16:59,950 --> 00:17:02,950
If not, we end and exit the agent loop.
如果没有，我们就结束并退出智能体循环。

251
00:17:02,950 --> 00:17:05,950
This is a very useful thing to be aware of.
这点很值得注意。

252
00:17:05,950 --> 00:17:08,950
Now let's see something else that's interesting.
接下来看些有趣的东西。

253
00:17:08,950 --> 00:17:13,109
This time, I initialize my graph with messages state.
这次，我用消息状态初始化图表。

254
00:17:13,109 --> 00:17:16,109
This is a prebuilt state object in line graph.
这是图表里预设的状态对象。

255
00:17:16,109 --> 00:17:18,109
That is a single key messages.
也就是一个关键信息。

256
00:17:18,109 --> 00:17:22,589
And when we update it, as you see here,
当我们更新它时，如你所见，

257
00:17:22,589 --> 00:17:26,779
it just simply depends to that list of messages
它只是简单地附加到消息列表，

258
00:17:26,779 --> 00:17:28,779
as opposed to overwriting.
而不是覆盖。

259
00:17:28,779 --> 00:17:31,980
Now this is also very useful when you're building agents
这在你构建代理时也非常有用，

260
00:17:31,980 --> 00:17:34,980
because you want to basically accumulate messages
因为你希望累积消息。

261
00:17:34,980 --> 00:17:39,259
over the course of the agent's tool calling trajectory.
在智能体的工具调用轨迹中。

262
00:17:39,259 --> 00:17:42,710
And you'll see in this should continue edge.
你们会看到，在“应继续”这个边缘，

263
00:17:42,710 --> 00:17:46,710
All we do is we get the last message
我们所做的就是获取消息列表中的

264
00:17:46,710 --> 00:17:48,809
from the list of messages.
最后一条消息。

265
00:17:48,809 --> 00:17:53,259
We check if it's a tool call.
我们检查它是否是工具调用。

266
00:17:53,259 --> 00:17:58,259
And if so, we return the name of the next node to go to run tool.
如果是，我们就返回下一个要运行的节点的名称。

267
00:17:58,259 --> 00:18:00,259
Otherwise, we end.
否则，就结束。

268
00:18:00,259 --> 00:18:02,609
So you'll see an interesting difference.
你们会看到一个有趣的差异。

269
00:18:03,609 --> 00:18:05,609
With conditional edges,
对于条件边，

270
00:18:05,609 --> 00:18:09,609
you return the name of the next node you want to visit.
你要返回下一个你想访问的节点的名称。

271
00:18:09,609 --> 00:18:11,769
But with nodes,
但对于节点，

272
00:18:11,769 --> 00:18:14,769
you return updates to your state.
你可以更新你的状态。

273
00:18:14,769 --> 00:18:17,769
So we'll compile this and show the graph.
我们来编译一下，展示图表。

274
00:18:17,769 --> 00:18:20,769
So now we start, we call our model.
现在我们开始，调用模型。

275
00:18:20,769 --> 00:18:23,769
And depending upon whether the model likes a tool call,
然后根据模型是否喜欢工具调用，

276
00:18:23,769 --> 00:18:25,769
we'll run the tool or not.
我们会运行工具与否。

277
00:18:25,769 --> 00:18:28,119
Let's go ahead and try that out.
我们来试试看。

278
00:18:28,119 --> 00:18:29,119
And there we go.
成功了。

279
00:18:29,119 --> 00:18:32,119
We pass our input message.
我们传入输入信息。

280
00:18:32,119 --> 00:18:34,180
Our model makes a tool call.
模型调用工具。

281
00:18:34,180 --> 00:18:37,180
We then route to the run tool node.
然后我们连接到运行工具节点。

282
00:18:37,180 --> 00:18:40,250
And the tool is run as we see here.
工具就会像这样运行。

283
00:18:40,250 --> 00:18:43,250
Now with just these local components,
仅用这些本地组件，

284
00:18:43,250 --> 00:18:45,250
you can build a lot of different things.
就能构建出许多不同的东西。

285
00:18:45,250 --> 00:18:48,470
Now because agents are so common,
因为代理很常见，

286
00:18:48,470 --> 00:18:50,470
we have a pre-built abstraction for it,
我们为此预设了一个抽象层，

287
00:18:50,470 --> 00:18:53,599
which I show right here called create react agent.
也就是我在这里展示的“创建React代理”。

288
00:18:53,599 --> 00:18:56,599
Now to this, agent abstraction,
现在，对于这个代理抽象层，

289
00:18:56,599 --> 00:18:59,599
we just pass our model, our list of tools,
我们只需传入模型、工具列表，

290
00:18:59,599 --> 00:19:01,599
and a system prompt.
以及一个系统提示。

291
00:19:01,599 --> 00:19:03,599
We run the agent just like before,
我们像之前一样运行代理，

292
00:19:03,599 --> 00:19:05,599
passing in messages.
传入消息。

293
00:19:05,599 --> 00:19:10,920
And we can see that the model in this case makes a tool call.
我们可以看到模型在这种情况下调用了工具。

294
00:19:10,920 --> 00:19:12,920
The tool is run.
工具开始运行。

295
00:19:12,920 --> 00:19:14,920
Now here's the little difference
现在，这里有个小区别

296
00:19:14,920 --> 00:19:15,920
relative that we saw before.
我们之前看到的亲戚。

297
00:19:15,920 --> 00:19:18,920
Remember before after tools run we just end.
记得吗，之前工具运行后我们直接结束了。

298
00:19:18,920 --> 00:19:22,140
With the agent though as discussed,
但对于代理，正如我们讨论的，

299
00:19:22,140 --> 00:19:25,140
tool calls are returned back to the LLM.
工具调用会返回给大型语言模型。

300
00:19:25,140 --> 00:19:27,529
So what happens is,
所以发生的情况是，

301
00:19:27,529 --> 00:19:29,529
the model then sees that tool call
模型会看到这个工具调用

302
00:19:29,529 --> 00:19:34,619
and provides us a response indicating the tools called
然后给我们一个响应，指出调用的工具

303
00:19:34,619 --> 00:19:37,750
and does not call any further tools.
并且不再调用任何其他工具。

304
00:19:37,750 --> 00:19:41,359
That then exits the tool calling loop
这样就退出了工具调用循环

305
00:19:41,359 --> 00:19:43,460
and the agent ends.
智能体也就结束了。

306
00:19:43,460 --> 00:19:46,710
So now we've seen the basic components of LLM graph.
我们已经了解了LLM图的基本组成部分。

307
00:19:46,710 --> 00:19:49,869
And we've introduced the agent abstraction to LLM graph.
也将代理抽象引入了LLM图。

308
00:19:49,869 --> 00:19:51,869
Now in a very important thing when building agents
构建代理和工作流时，

309
00:19:51,869 --> 00:19:54,869
and workflows, as we're going to see a lot more later,
有一个非常重要的概念，我们稍后会详细介绍，

310
00:19:54,869 --> 00:19:56,869
is the idea of persistence.
那就是持久性。

311
00:19:56,869 --> 00:19:58,970
It can be very useful to allow agents
让智能体在执行

312
00:19:58,970 --> 00:20:02,160
to pause during long-running tasks.
耗时任务时暂停，会非常有用。

313
00:20:02,160 --> 00:20:04,160
Minecraft has a built-in persistence layer
Minecraft 有内置的持久层

314
00:20:04,160 --> 00:20:07,259
to enable this, implemented through check pointers.
可以实现这个功能，通过检查点实现。

315
00:20:07,259 --> 00:20:10,289
Now what happens is, after every node,
现在，每经过一个节点，

316
00:20:10,289 --> 00:20:13,450
the check pointer saves the state of the graph.
检查点会保存图的状态。

317
00:20:13,450 --> 00:20:15,450
So if you pause your graph,
所以如果你暂停图，

318
00:20:15,450 --> 00:20:17,450
the state is saved and available
它的状态就会被保存下来，

319
00:20:17,450 --> 00:20:19,450
for resuming in a later point in time.
方便之后恢复。

320
00:20:19,450 --> 00:20:21,450
Now let's show an example of this.
现在我们来看一个例子。

321
00:20:21,450 --> 00:20:24,859
I can take that same create react agent abstraction
我可以用同样的“create react agent”抽象

322
00:20:24,859 --> 00:20:26,930
and pass it a check pointer.
然后给它一个检查点。

323
00:20:26,930 --> 00:20:30,220
I'll ask something about good practices
我会问一些关于写邮件的好习惯。

324
00:20:30,220 --> 00:20:32,410
for writing emails.
写邮件的好习惯。

325
00:20:32,410 --> 00:20:33,410
Now with a check pointer,
现在有了检查点，

326
00:20:33,410 --> 00:20:36,410
you'll see I need to now pass a thread ID.
你会看到我需要传入一个线程ID。

327
00:20:36,410 --> 00:20:39,410
This basically groups checkpoints together
这基本上把检查点归类到一起，

328
00:20:39,410 --> 00:20:41,410
so I can reference them later.
这样我以后可以引用它们。

329
00:20:41,410 --> 00:20:42,410
Our agent ran.
我们的代理运行了。

330
00:20:42,410 --> 00:20:44,440
And what's really nice is,
真正好的是，

331
00:20:44,440 --> 00:20:47,470
we can get this current state of our agent
我们可以获取智能体的当前状态

332
00:20:47,470 --> 00:20:50,470
just by passing in the thread.
只要传入线程。

333
00:20:50,470 --> 00:20:53,700
We'll call agent.getState.
我们会调用agent.getState。

334
00:20:53,700 --> 00:20:55,700
And we can go ahead and extract
然后我们可以提取

335
00:20:55,700 --> 00:20:58,700
all the messages currently in state of our agent.
智能体当前状态中的所有消息。

336
00:20:58,700 --> 00:21:00,700
Now currently we see we just have our input
现在我们看到，我们只有输入

337
00:21:00,700 --> 00:21:05,200
and we have the agent's response.
和智能体的回复。

338
00:21:05,200 --> 00:21:08,519
Now let's continue the conversation.
现在我们继续对话。

339
00:21:08,519 --> 00:21:11,650
All I need to do is re-invoke my agent
我只需要重新调用我的智能体

340
00:21:11,650 --> 00:21:12,650
and I'll say, hey great,
然后我会说，太棒了，

341
00:21:12,650 --> 00:21:14,650
let's use lesson three,
我们用第三课

342
00:21:14,650 --> 00:21:18,650
be concise to craft a response to my boss
简洁地回复老板

343
00:21:18,650 --> 00:21:21,779
and I can just pass in the config.
我可以直接传入配置

344
00:21:21,779 --> 00:21:24,900
That config indicates the thread.
该配置表示线程

345
00:21:24,900 --> 00:21:28,160
If I can run, we can see the agent then
如果我能运行，我们就能看到代理

346
00:21:28,160 --> 00:21:32,319
has access to the prior messages
它可以访问之前的消息

347
00:21:32,319 --> 00:21:34,319
because they're saved to the thread
因为它们都保存在对话串里

348
00:21:34,319 --> 00:21:36,319
and it proposes an email.
然后它会生成一封邮件。

349
00:21:36,319 --> 00:21:39,799
I can then follow up again
我就可以继续操作

350
00:21:39,799 --> 00:21:41,799
by passing in that thread ID
传入那个对话串ID

351
00:21:41,799 --> 00:21:43,799
and say I like this.
然后说我喜欢这个。

352
00:21:43,799 --> 00:21:46,089
Go ahead and write the email.
你去写这封邮件。

353
00:21:46,089 --> 00:21:48,089
And now you can see it goes ahead,
现在你可以看到它会

354
00:21:48,089 --> 00:21:50,339
calls the tool.
调用工具。

355
00:21:50,339 --> 00:21:52,339
The tool is executed
工具已执行

356
00:21:52,339 --> 00:21:56,109
and it confirms that the email has been sent.
确认邮件已发送。

357
00:21:56,109 --> 00:21:59,529
Now another very powerful thing
另外一个非常强大的功能

358
00:21:59,529 --> 00:22:01,529
that check pointing allows
是检查点允许

359
00:22:01,529 --> 00:22:02,529
is that we can interrupt our graph
我们中断图表

360
00:22:02,529 --> 00:22:05,849
at very specific points.
在非常特定的点。

361
00:22:05,849 --> 00:22:07,849
Here's an example of a very simple graph
这是一个非常简单的图表示例

362
00:22:07,849 --> 00:22:08,849
where I want to interrupt
我想在这里中断

363
00:22:08,849 --> 00:22:10,849
at a particular node human feedback
在特定节点处进行人工反馈

364
00:22:10,849 --> 00:22:14,069
to collect feedback from the user.
以收集用户的反馈。

365
00:22:14,069 --> 00:22:18,200
All you do is add this interrupt object
你只需添加这个中断对象

366
00:22:18,200 --> 00:22:20,200
to the node
到节点

367
00:22:20,200 --> 00:22:23,619
and compile my graph with a checkpointer.
用检查点编译图表。

368
00:22:23,619 --> 00:22:26,000
We can see our graph flow here.
我们能看到图表流程。

369
00:22:26,000 --> 00:22:28,000
We'll create a thread like before.
我们会像之前一样创建线程。

370
00:22:28,000 --> 00:22:30,000
We'll run a graph.
我们会运行图表。

371
00:22:30,000 --> 00:22:33,130
Now I'll just simply stream updates
现在我只需简单地

372
00:22:33,130 --> 00:22:35,130
to each node as the graph is running
将更新流式传输到每个节点

373
00:22:35,130 --> 00:22:38,130
by indicating the stream mode updates.
通过指示流模式更新。

374
00:22:38,130 --> 00:22:40,130
Now it's interesting here
有趣的是

375
00:22:40,130 --> 00:22:43,130
when we hit that human feedback node,
当我们触及人工反馈节点时，

376
00:22:43,130 --> 00:22:46,130
we can see the graph emits an interrupt.
图表发出中断

377
00:22:46,130 --> 00:22:49,130
With a value, please provide feedback
请给出反馈值

378
00:22:49,130 --> 00:22:51,130
and that's exactly what we passed to
这正是我们传给

379
00:22:51,130 --> 00:22:53,420
that interrupt object.
中断对象的参数

380
00:22:53,420 --> 00:22:54,420
Now to resume,
现在，要恢复

381
00:22:54,420 --> 00:22:56,420
all you need to do is use this command object
你只需使用这个命令对象

382
00:22:56,420 --> 00:22:58,420
in the line graph
在折线图中

383
00:22:58,420 --> 00:23:01,420
and pass in whatever human feedback I want.
传入我想要的任何人工反馈。

384
00:23:01,420 --> 00:23:03,579
Now to resume from the interrupt,
现在要从中断中恢复，

385
00:23:03,579 --> 00:23:05,579
we just invoke our graph again
我们只需再次调用图表

386
00:23:05,579 --> 00:23:06,579
with the command object
用命令对象

387
00:23:06,579 --> 00:23:08,990
and we pass resume.
然后传入resume

388
00:23:08,990 --> 00:23:11,339
We can simply pass a string
我们直接传入字符串

389
00:23:11,339 --> 00:23:13,339
and our feedback gets passed through
我们的反馈会传递给

390
00:23:13,339 --> 00:23:14,339
to our node
我们的节点

391
00:23:14,339 --> 00:23:16,339
and written to our state
并写入到我们的状态中

392
00:23:16,339 --> 00:23:19,400
as user feedback.
作为用户反馈。

393
00:23:19,400 --> 00:23:20,400
So whatever we pass
所以我们传递的任何内容

394
00:23:20,400 --> 00:23:22,460
to this resume
到这个简历中

395
00:23:22,460 --> 00:23:24,460
and command after an interrupt
并在中断后发出命令

396
00:23:24,460 --> 00:23:27,910
is directly passed into our graph.
直接传入我们的图表。

397
00:23:27,910 --> 00:23:30,329
And what we can see right here
我们现在能看到的是

398
00:23:30,329 --> 00:23:33,329
is where we received that feedback,
我们收到反馈的地方，

399
00:23:33,329 --> 00:23:35,900
run it to state.
将其运行到某个状态。

400
00:23:35,900 --> 00:23:39,099
Now because I set these two environment variables,
因为我设置了这两个环境变量，

401
00:23:39,099 --> 00:23:41,130
everything we just did
我们刚才做的一切

402
00:23:41,130 --> 00:23:43,130
is logged to Langsmith.
都记录在Langsmith里了。

403
00:23:43,130 --> 00:23:45,640
I can then look at my Langsmith traces
我可以查看Langsmith的追踪记录

404
00:23:45,640 --> 00:23:47,640
for any of the above executions.
看看上面任何一次执行。

405
00:23:47,640 --> 00:23:51,019
Here's an example looking at our agent
这是一个查看我们代理的例子

406
00:23:51,019 --> 00:23:53,019
and we see here in Langsmith.
我们在Langsmith里看到

407
00:23:53,019 --> 00:23:55,089
Here are graph nodes for our agent.
这是我们代理的图节点。

408
00:23:55,089 --> 00:23:57,309
We can open this up.
我们可以打开它。

409
00:23:57,309 --> 00:24:00,309
This shows us the model call specifically.
这具体展示了模型调用。

410
00:24:00,309 --> 00:24:01,309
Open that up.
打开它。

411
00:24:01,309 --> 00:24:04,789
And you can see here are the bound tools.
你可以看到，这是绑定工具。

412
00:24:04,789 --> 00:24:08,079
We actually called the right email tool right here.
我们称之为“右键邮件工具”。

413
00:24:08,079 --> 00:24:10,079
Here is a list of messages,
这里是消息列表，

414
00:24:10,079 --> 00:24:12,559
the L and received.
已发送和已接收的。

415
00:24:12,559 --> 00:24:14,559
And then here is the resulting tool call.
然后是工具调用的结果。

416
00:24:14,559 --> 00:24:16,779
We then went to the tool node,
然后我们来到工具节点，

417
00:24:16,779 --> 00:24:17,779
open that up,
打开它，

418
00:24:17,779 --> 00:24:19,779
and you can see here is the tool in vocation
你会看到这是工具的调用

419
00:24:19,779 --> 00:24:21,849
and the output of our tool
以及我们工具的输出

420
00:24:21,849 --> 00:24:23,849
as a tool message.
作为一条工具消息。

421
00:24:23,849 --> 00:24:26,329
And finally, that went back to our agent.
最后，它回到了我们的代理。

422
00:24:26,329 --> 00:24:28,329
We can see that call model,
我们可以看到那个调用模型，

423
00:24:28,329 --> 00:24:30,519
node,
节点，

424
00:24:30,519 --> 00:24:32,519
we can look at the L and call specifically,
我们可以专门看看L和调用，

425
00:24:32,519 --> 00:24:34,519
see that node tools called
看看那个节点工具调用

426
00:24:34,519 --> 00:24:37,519
and a module response
模块会响应

427
00:24:37,519 --> 00:24:39,619
with an IAM message saying
一条IAM消息

428
00:24:39,619 --> 00:24:41,940
that email has been sent.
说邮件已发送。

429
00:24:41,940 --> 00:24:44,940
So Langsmith is very nice way to dig into your traces
Langsmith能很好地帮你追踪

430
00:24:44,940 --> 00:24:48,190
and it also logs useful metadata for you
还能记录有用的元数据

431
00:24:48,190 --> 00:24:50,190
as you can see over here.
大家可以看到

432
00:24:50,190 --> 00:24:52,349
Now in addition to Langsmith,
除了Langsmith

433
00:24:52,349 --> 00:24:54,480
I want to talk about another important
我还想谈谈另一个

434
00:24:54,480 --> 00:24:57,480
and useful feature in the Langtrain ecosystem
Langchain生态系统中的重要功能

435
00:24:57,480 --> 00:25:00,700
that allows us to deploy agents
它可以部署智能体

436
00:25:00,700 --> 00:25:02,700
or workflows very easily.
或工作流。

437
00:25:02,700 --> 00:25:04,700
And that's called Langarth platform.
这就是Langarth平台。

438
00:25:04,700 --> 00:25:07,279
So everything we've done here in a notebook
我们在笔记本里做的一切

439
00:25:07,279 --> 00:25:09,279
is great for testing
都很适合测试

440
00:25:09,279 --> 00:25:12,470
and for rapid prototyping.
和快速原型开发。

441
00:25:12,470 --> 00:25:14,470
But what if I want to turn any of this code
但如果我想把这些代码

442
00:25:14,470 --> 00:25:17,470
into a deployable application?
变成可部署的应用呢？

443
00:25:17,470 --> 00:25:19,789
That's where Langarth platform comes in.
这就是Langarth平台的作用。

444
00:25:19,789 --> 00:25:22,109
It makes it very easy to go
它让这一切变得非常容易，

445
00:25:22,109 --> 00:25:24,430
from workflow agents to
从工作流代理到

446
00:25:25,430 --> 00:25:27,880
a deployable server
一个可部署的服务器

447
00:25:27,880 --> 00:25:30,880
with an API that we can use to interact with our graph.
通过API与图数据交互。

448
00:25:30,880 --> 00:25:32,200
In addition,
此外，

449
00:25:32,200 --> 00:25:34,200
Langarth platform gives us
Langarth平台还提供

450
00:25:34,200 --> 00:25:36,200
an interactive IDE called Langarth Studio.
一个交互式IDE，叫Langarth Studio。

451
00:25:36,200 --> 00:25:39,200
It's a very useful way to further inspect
这是一个非常有用的方法，可以进一步检查

452
00:25:39,200 --> 00:25:41,460
and debug our agent.
和调试我们的代理。

453
00:25:41,460 --> 00:25:43,809
So to use Langarth platform,
要使用Langsmith平台，

454
00:25:43,809 --> 00:25:45,809
all we need to do is ensure that our project
我们需要做的就是确保我们的项目

455
00:25:45,809 --> 00:25:48,059
has a structure as shown here.
具有如图所示的结构。

456
00:25:48,059 --> 00:25:50,059
So the thing that really matters here
最重要的是

457
00:25:50,059 --> 00:25:52,160
is this Langarth.json.
这个Langarth.json文件。

458
00:25:52,160 --> 00:25:54,160
This is just a configuration file.
它只是一个配置文件。

459
00:25:54,160 --> 00:25:56,319
In the root of this repo,
在这个仓库的根目录里，

460
00:25:56,319 --> 00:25:58,319
this just specifies dependencies, graphs,
它只指定了依赖项、图表，

461
00:25:58,319 --> 00:25:59,319
environment variables,
环境变量，

462
00:25:59,319 --> 00:26:01,319
and other things needed to start
以及启动

463
00:26:01,319 --> 00:26:03,319
the Langarth server.
Langarth服务器所需的其他东西。

464
00:26:03,319 --> 00:26:05,319
It's a pretty simple configuration.
这是一个相当简单的配置。

465
00:26:05,319 --> 00:26:07,319
The main thing the configuration will have
配置主要包含

466
00:26:07,319 --> 00:26:10,349
is just simply the graph names
只是图表名称

467
00:26:10,349 --> 00:26:12,509
and the path.
和路径。

468
00:26:12,509 --> 00:26:13,509
As an example,
举个例子，

469
00:26:13,509 --> 00:26:15,670
in a repo,
在一个仓库里，

470
00:26:15,670 --> 00:26:16,670
in this directory,
在这个目录下，

471
00:26:16,670 --> 00:26:19,859
we have a file called Langarth 101.py,
我们有个文件叫Langarth 101.py，

472
00:26:19,859 --> 00:26:21,859
which contains some of the code
里面包含一些代码

473
00:26:21,859 --> 00:26:24,410
that we just prototyped in this notebook
是我们刚在这个笔记本里

474
00:26:24,410 --> 00:26:26,789
as a deployable graph.
作为可部署图表原型化的。

475
00:26:26,789 --> 00:26:27,789
Now with Langarth platform,
现在有了Langarth平台，

476
00:26:27,789 --> 00:26:29,789
there's a few different deployment options.
有几种不同的部署方式。

477
00:26:29,789 --> 00:26:31,890
I want to make sure our clear.
我想确保我们讲清楚。

478
00:26:31,890 --> 00:26:34,890
So the simplest and free option is just local deployment
最简单、免费的方式是本地部署，

479
00:26:34,890 --> 00:26:36,890
that runs on your local machine,
它在你的本地机器上运行，

480
00:26:36,890 --> 00:26:38,890
and all I need to do from the root of this directory
我只需要在这个目录的根目录下

481
00:26:38,890 --> 00:26:41,210
is run Langarth dev.
是运行Langarth开发版。

482
00:26:41,210 --> 00:26:43,210
Now this still has persistence,
它现在仍有持久性，

483
00:26:43,210 --> 00:26:46,529
checkpoints should be written to the local file system.
检查点应该写入本地文件系统。

484
00:26:46,529 --> 00:26:49,529
Now they're also very self-hosted options for deployment,
也有很多自托管部署选项，

485
00:26:49,529 --> 00:26:51,529
and there's hosted deployments,
还有托管部署，

486
00:26:51,529 --> 00:26:53,750
which use Postgres,
使用Postgres

487
00:26:53,750 --> 00:26:55,069
for persistence.
进行持久化。

488
00:26:55,069 --> 00:26:57,069
So we'll just run Langarth dev
所以我们直接在

489
00:26:57,069 --> 00:26:59,140
from the root of our repo,
仓库根目录运行Langarth dev，

490
00:26:59,140 --> 00:27:00,140
and see what happens.
看看会发生什么。

491
00:27:00,140 --> 00:27:02,549
So if we run Langarth dev,
运行Langarth dev后，

492
00:27:02,549 --> 00:27:04,549
you'll see this spin up in your browser.
浏览器会弹出这个界面。

493
00:27:04,549 --> 00:27:06,970
This is Langarth Studio.
这是Langarth Studio。

494
00:27:06,970 --> 00:27:08,970
You can scroll through the various graphs
你可以浏览各种图表，

495
00:27:08,970 --> 00:27:10,970
that are existence repo.
它们都存在于repo中。

496
00:27:10,970 --> 00:27:13,289
Click on Langarth 101.
点击“朗加斯101”。

497
00:27:13,289 --> 00:27:16,289
This is one of the graphs we built in the notebook.
这是我们在笔记本中构建的图表之一。

498
00:27:16,289 --> 00:27:18,670
We can open up this input pane,
我们可以打开这个输入窗格，

499
00:27:18,670 --> 00:27:19,670
open up messages,
打开消息，

500
00:27:19,670 --> 00:27:20,670
pass in a message,
传入一条消息，

501
00:27:20,670 --> 00:27:21,670
submit,
提交，

502
00:27:21,670 --> 00:27:23,769
and you can see the state of the graph
就能看到图的状态

503
00:27:23,769 --> 00:27:25,900
over here,
在这里，

504
00:27:25,900 --> 00:27:27,900
which shows each node in the graph,
它显示了图中的每个节点，

505
00:27:27,900 --> 00:27:28,900
as well as the state updates,
以及状态更新，

506
00:27:28,900 --> 00:27:31,119
at that particular node.
在那个特定节点。

507
00:27:31,119 --> 00:27:34,440
You can also click on this open-run Langsmiths,
你也可以点击“打开运行Langsmiths”，

508
00:27:34,440 --> 00:27:38,019
and look at the trace to see the LM call,
查看轨迹，了解语言模型调用，

509
00:27:38,019 --> 00:27:39,019
in the call LM node,
在调用语言模型节点中，

510
00:27:39,019 --> 00:27:42,019
as well as the tool execution in the run tool node.
以及在运行工具节点中的工具执行。

511
00:27:42,019 --> 00:27:45,039
Now another nice thing I'll point out
另外，我还想指出一点

512
00:27:45,039 --> 00:27:48,809
is that you can see the API docs for your local deployment,
你可以在这里看到本地部署的API文档，

513
00:27:48,809 --> 00:27:49,809
right here,
就在这儿，

514
00:27:49,809 --> 00:27:52,420
and you can browse through
你可以浏览一下

515
00:27:52,420 --> 00:27:54,420
to see all the endpoints available to you.
看看所有可用的端点。

516
00:27:54,420 --> 00:27:56,420
So we've covered many of the foundations needed
我们已经讲了这门课的很多基础知识

517
00:27:56,420 --> 00:27:58,480
for this course.
了。

518
00:27:58,480 --> 00:28:00,740
We've covered Langchain
我们讲了Langchain

519
00:28:00,740 --> 00:28:01,740
in some of the useful interfaces,
和一些有用的接口，

520
00:28:01,740 --> 00:28:03,740
such as init chat model,
比如init chat model，

521
00:28:03,740 --> 00:28:05,059
tools,
工具，

522
00:28:05,059 --> 00:28:07,150
and using chat models.
以及聊天模型。

523
00:28:07,150 --> 00:28:10,150
We've talked about the basis of Langarth
我们讨论了LangChain的基础

524
00:28:10,150 --> 00:28:12,150
and agents versus workflows.
以及代理和工作流的区别。

525
00:28:12,150 --> 00:28:14,150
We also showed both Langsmith,
我们还展示了LangSmith，

526
00:28:14,150 --> 00:28:16,150
as well as Langarth deployment
以及Langarth部署

527
00:28:16,150 --> 00:28:18,150
and Langarth Studio.
和Langarth Studio。

528
00:28:18,150 --> 00:28:20,150
We covered persistence and interrupts.
我们讲了持久性和中断。

529
00:28:20,150 --> 00:28:24,410
We also covered Langsmith and observability,
我们还讲了Langsmith和可观测性，

530
00:28:24,410 --> 00:28:26,410
as well as Langarth platform,
以及Langarth平台，

531
00:28:26,410 --> 00:28:28,410
showcasing local deployments,
展示本地部署，

532
00:28:28,410 --> 00:28:30,569
and Langarth Studio.
以及Langarth Studio。

533
00:28:30,569 --> 00:28:31,569
So these are really all the foundations
这些都是你接下来课程中

534
00:28:31,569 --> 00:28:34,569
you're going to need for the rest of this course.
需要用到的所有基础知识。
