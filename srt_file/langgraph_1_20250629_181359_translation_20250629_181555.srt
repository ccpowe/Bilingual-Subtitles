1
00:00:00,000 --> 00:00:05,160
欢迎来到我们的新课程：Line Chain学院，用Line Graph构建代理。

2
00:00:05,160 --> 00:00:11,160
聊天是代理中常见的用户交互模式，用户向代理提出请求，

3
00:00:11,160 --> 00:00:16,190
代理可以调用各种工具，并向用户输出响应。

4
00:00:16,190 --> 00:00:21,289
但有很多任务不适合用聊天模式。

5
00:00:21,289 --> 00:00:26,289
例如，许多用户并不想真正告诉代理该做什么。

6
00:00:26,289 --> 00:00:32,420
他们希望代理能被动监听特定事件，并自动响应。

7
00:00:32,420 --> 00:00:37,420
很多时候，我们不希望代理一次只处理一个请求。

8
00:00:37,420 --> 00:00:40,420
我们可能希望代理能同时处理许多事件。

9
00:00:40,420 --> 00:00:44,420
有时我们希望代理能在后台为我们工作，

10
00:00:44,420 --> 00:00:49,420
只在特定时刻通知我们，比如工作完成时，

11
00:00:49,420 --> 00:00:55,579
当他们需要澄清某事，或想通知我们某事时。

12
00:00:55,579 --> 00:01:01,609
最后，对于聊天，你通常希望客服能快速处理。

13
00:01:01,609 --> 00:01:06,829
但如果客服在后台处理，可能要花更长时间。

14
00:01:06,829 --> 00:01:11,829
用户不用一直等着。客服只会在适当的时候通知他们。

15
00:01:11,829 --> 00:01:16,120
所以这些属性的集合，我们称之为“环境代理”。

16
00:01:16,120 --> 00:01:21,150
本课程中，我们将构建一个环境智能体，能处理电子邮件，

17
00:01:21,150 --> 00:01:26,150
这是这类智能体可能承担的绝佳任务范例。

18
00:01:26,150 --> 00:01:31,500
它将构建一个能有效管理你电子邮件收件箱的智能体。

19
00:01:31,500 --> 00:01:38,540
它会接收传入的电子邮件，并执行诸如起草回复或安排会议等操作。

20
00:01:38,540 --> 00:01:45,659
因为这些是敏感任务，我们将展示如何使用人工审核来批准某些智能体操作。

21
00:01:46,659 --> 00:01:52,659
重要的是，我们还会引入记忆功能，让智能体能从我们的反馈中不断学习。

22
00:01:52,659 --> 00:01:57,019
学完这门课，你就能理解所有这些组件

23
00:01:57,019 --> 00:02:01,019
以及它们如何被普遍用于构建智能体，不只是处理邮件的智能体，

24
00:02:01,019 --> 00:02:04,459
还能处理许多不同类型的任务。

25
00:02:04,459 --> 00:02:06,459
那么，我们究竟该如何构建它呢？

26
00:02:06,459 --> 00:02:09,659
假设我们有一个最简单的邮件系统。

27
00:02:09,659 --> 00:02:14,659
每收到一封邮件，助手就会生成一封回复邮件。

28
00:02:14,659 --> 00:02:18,689
助手可以通过调用工具发送回复，

29
00:02:18,689 --> 00:02:20,689
我稍后会简单介绍一下。

30
00:02:20,689 --> 00:02:24,689
如果你从“自主性”和“可预测性”的角度来思考这个系统，

31
00:02:24,689 --> 00:02:29,689
代理能力是指系统做出不同决策的能力，可预测性则是指

32
00:02:29,689 --> 00:02:32,689
系统做出决策的可预测性。

33
00:02:32,689 --> 00:02:35,689
这就是低代理能力但高可预测性。

34
00:02:35,689 --> 00:02:41,689
它会为收到的每封邮件调用工具发送邮件。

35
00:02:41,689 --> 00:02:46,689
这个系统和更广泛的代理的核心概念是工具调用。

36
00:02:46,689 --> 00:02:49,689
假设我们有一个邮件API。

37
00:02:49,689 --> 00:02:51,689
比如Gmail API。

38
00:02:51,689 --> 00:02:56,689
我们可以把它变成一个工具，然后绑定到大型语言模型（LLM）上。

39
00:02:56,689 --> 00:03:04,819
在绑定过程中，LLM会理解调用这个工具所需的参数。

40
00:03:04,819 --> 00:03:06,819
所以当它收到请求时，

41
00:03:06,819 --> 00:03:12,039
它会分析请求，然后决定是否调用工具，

42
00:03:12,039 --> 00:03:15,039
但重要的是，它会生成结构化输出，

43
00:03:15,039 --> 00:03:19,039
其中包含工具实际所需的参数。

44
00:03:19,039 --> 00:03:25,039
之后，工具可以独立地用这些参数执行，

45
00:03:25,039 --> 00:03:27,039
在这个例子中，就是发送一封邮件。

46
00:03:27,039 --> 00:03:33,039
值得注意的是，一个简单的系统，如果总是调用邮件工具，会很受限。

47
00:03:33,039 --> 00:03:35,389
如果我们不想回复呢？

48
00:03:36,550 --> 00:03:42,550
所以人们找到了许多有效的方法来规划工作流程。

49
00:03:42,550 --> 00:03:47,550
这只是预定义代码路径中的LLM调用。

50
00:03:47,550 --> 00:03:50,650
它可以实现特定的逻辑。

51
00:03:50,650 --> 00:03:59,000
举个例子，我们在调用发送邮件工具前，

52
00:03:59,000 --> 00:04:04,060
先放了一个路由器，它会决定是否发送邮件。

53
00:04:04,060 --> 00:04:11,060
如果决定发送，我们就会继续执行刚才说的，

54
00:04:11,060 --> 00:04:15,319
让大语言模型访问邮件工具，然后发送邮件。

55
00:04:15,319 --> 00:04:19,379
如果你考虑这个系统，我们稍微提升了它的自主性。

56
00:04:19,379 --> 00:04:21,379
现在它能做决定了。

57
00:04:21,379 --> 00:04:24,959
它能决定是否回应。

58
00:04:24,959 --> 00:04:26,959
反过来，它就没那么可预测了。

59
00:04:26,959 --> 00:04:32,180
我们不知道它收到邮件后会怎么决定。

60
00:04:32,180 --> 00:04:35,220
现在我们再进一步。

61
00:04:35,220 --> 00:04:39,220
设想我们用那个大型语言模型，不是只给它一个工具，比如写邮件，

62
00:04:39,220 --> 00:04:42,220
而是给它一堆不同的工具。

63
00:04:42,220 --> 00:04:49,339
每次它调用一个工具，我们就把那个工具调用的输出返回给大型语言模型。

64
00:04:49,339 --> 00:04:54,339
我们让大型语言模型思考执行了什么，然后决定下一步做什么。

65
00:04:54,339 --> 00:04:58,569
我们让这个过程循环进行，直到某个终止条件。

66
00:04:58,569 --> 00:05:00,569
简单来说，它是一个代理。

67
00:05:00,569 --> 00:05:05,569
如前所述，它的代理能力比另外两个强很多。

68
00:05:05,569 --> 00:05:10,790
有个方法可以直观地看出，

69
00:05:10,790 --> 00:05:17,019
对于初始系统，每收到一封邮件，它只做一个决定，就是写回复并发送。

70
00:05:17,019 --> 00:05:25,240
相比之下，这个代理可以根据它能使用的工具，选择任意的工具调用序列。

71
00:05:25,240 --> 00:05:28,240
假设它能用三个工具。

72
00:05:28,240 --> 00:05:30,240
查看日历、安排会议、写邮件。

73
00:05:30,240 --> 00:05:32,339
它可以根据邮件内容。

74
00:05:32,339 --> 00:05:34,339
自由选择顺序。

75
00:05:34,339 --> 00:05:39,339
那么，工作流或代理要怎么考虑呢？

76
00:05:39,339 --> 00:05:44,689
通常，一个好的指标是，你能在白板上轻松画出控制流

77
00:05:44,689 --> 00:05:48,689
而且它很容易在高级工作流中进行计数

78
00:05:48,689 --> 00:05:54,100
通常比代理的延迟和成本更低。

79
00:05:54,100 --> 00:05:57,100
但如果你需要更灵活的决策，

80
00:05:57,100 --> 00:06:01,230
而且在运行时才能确定，

81
00:06:01,230 --> 00:06:04,420
或者在这种情况下，直到你收到一封邮件，

82
00:06:04,420 --> 00:06:07,420
你想如何用工具调用来回应，

83
00:06:07,420 --> 00:06:09,420
那么代理更合适。

84
00:06:09,420 --> 00:06:15,810
权衡更高的推理能力以换取更高的延迟和潜在的更高成本是可以接受的。

85
00:06:15,810 --> 00:06:20,810
现在，Line Graph之所以出现，是因为它是一个由低级组件组成的框架。

86
00:06:20,810 --> 00:06:26,000
让你灵活地构建和组合工作流和代理。

87
00:06:26,000 --> 00:06:31,129
线图由节点和边组成，节点只是工作单元。

88
00:06:31,129 --> 00:06:37,259
有你明确控制的Python函数或TypeScript代码。

89
00:06:37,259 --> 00:06:40,290
所以你只需编写这些函数，稍后你就会看到。

90
00:06:40,290 --> 00:06:44,579
一切都通过节点发生，你拥有完全的控制权。

91
00:06:44,579 --> 00:06:47,639
边是节点之间的转换，

92
00:06:47,639 --> 00:06:51,639
你可以在构建工作流编排时提前布局。

93
00:06:51,639 --> 00:06:54,639
这将决定应用程序的控制流。

94
00:06:54,639 --> 00:07:01,639
线图的一个好处是，因为它使用非常底层的组件，

95
00:07:01,639 --> 00:07:08,019
仅仅是节点和边，你就可以非常容易地构建许多不同的工作流和代理。

96
00:07:08,019 --> 00:07:12,410
你可以沿着这条曲线，随意选择座位。

97
00:07:12,410 --> 00:07:15,410
你可以构建纯粹的代理系统。

98
00:07:15,410 --> 00:07:17,410
你可以构建工作流。

99
00:07:17,410 --> 00:07:20,410
你可以将代理和工作流结合起来。

100
00:07:20,410 --> 00:07:24,439
我们在线图里加入了这个功能，我们觉得它很重要，

101
00:07:24,439 --> 00:07:27,439
特别是，我们将会看到，构建一个环境智能体，

102
00:07:27,439 --> 00:07:33,500
是一个持久层，它能让智能体拥有人类的循环和长期记忆。

103
00:07:33,500 --> 00:07:40,660
我们会看到，在许多情况下，智能体能暂停并获得人类反馈，这很重要。

104
00:07:40,660 --> 00:07:43,660
而这正是持久层所提供的。

105
00:07:43,660 --> 00:07:48,759
不仅如此，它还赋予了我们长期记忆。

106
00:07:48,759 --> 00:07:52,759
持久化的核心思想是检查点。

107
00:07:52,759 --> 00:07:56,759
就像你看到的，当你把图表布置成一组节点时，

108
00:07:56,759 --> 00:08:01,759
检查点会保存应用程序的状态。

109
00:08:01,759 --> 00:08:06,759
如果我们暂停，这个状态可以供我们以后恢复。

110
00:08:06,759 --> 00:08:11,430
线图还内置了交互式开发环境，

111
00:08:11,430 --> 00:08:15,430
Line Graph Studio，你会在本课程中大量看到它。

112
00:08:15,430 --> 00:08:18,430
它提供了一个简单的部署方式。

113
00:08:18,430 --> 00:08:22,430
你会看到我们可以非常轻松地将笔记本中运行的代码

114
00:08:22,430 --> 00:08:24,430
转换为可部署的应用程序。

115
00:08:24,430 --> 00:08:26,980
在我实际构建我们的代理之前，

116
00:08:26,980 --> 00:08:30,980
我想确保大家对“线图”的基础知识有清晰的理解，

117
00:08:30,980 --> 00:08:33,980
以及它如何与LangChain和LangSmith协同工作。

118
00:08:34,980 --> 00:08:37,980
这是三者结合的示意图。

119
00:08:37,980 --> 00:08:43,200
LangChain提供了许多我们将用到的集成，特别是聊天模型，

120
00:08:43,200 --> 00:08:49,679
还有一些非常有用的方法，用于绑定工具或结构化输出。

121
00:08:49,679 --> 00:08:52,679
线性图将用于代理编排。

122
00:08:52,679 --> 00:08:58,870
Langsmith 用于可观测性，比如追踪和评估。

123
00:08:58,870 --> 00:09:02,870
稍后你会看到，这三者配合得天衣无缝，

124
00:09:02,870 --> 00:09:04,870
它们就是这样关联的。

125
00:09:04,870 --> 00:09:08,289
现在，聊天模型是大型语言模型应用的基础。

126
00:09:08,289 --> 00:09:11,480
它们通常通过聊天界面访问，

127
00:09:11,480 --> 00:09:13,480
聊天界面接收消息列表输入，

128
00:09:13,480 --> 00:09:15,480
返回消息输出，

129
00:09:15,480 --> 00:09:20,669
以及LangChain用于聊天模型的标准接口，名为“init chat model”，

130
00:09:20,669 --> 00:09:25,740
你只需传入提供商和模型的名称即可。

131
00:09:25,740 --> 00:09:29,740
以及任何你想用的参数。

132
00:09:29,740 --> 00:09:33,250
LangChain有一些通用的方法

133
00:09:33,250 --> 00:09:36,629
可以访问聊天模型。

134
00:09:36,629 --> 00:09:40,629
Invoke只是将单个输入传递给聊天模型并返回一个输出。

135
00:09:40,629 --> 00:09:44,950
在这种情况下，我们只需传递一个字符串，在底层，

136
00:09:44,950 --> 00:09:47,950
它会转换成聊天消息，然后发送给我们。

137
00:09:47,950 --> 00:09:51,269
我们可以看到收到了一条消息。

138
00:09:51,269 --> 00:09:55,370
这就是那条消息，你可以看到它有这些内容，

139
00:09:55,370 --> 00:09:57,370
还有响应元数据。

140
00:09:57,370 --> 00:10:00,370
之前提到过，工具

141
00:10:00,370 --> 00:10:03,370
它们是聊天模型可以调用的实用程序。

142
00:10:03,370 --> 00:10:06,820
我们可以用LangChain轻松创建工具，

143
00:10:06,820 --> 00:10:11,820
比如用这个工具装饰器，从Python函数创建。

144
00:10:11,820 --> 00:10:16,230
现在，这个函数就是一个工具，

145
00:10:16,230 --> 00:10:20,230
当我们这样做时，工具参数以及描述，

146
00:10:20,230 --> 00:10:22,230
会自动推断。

147
00:10:22,230 --> 00:10:25,299
这些参数会传递给模型，

148
00:10:25,299 --> 00:10:29,299
让模型知道这个工具需要什么。

149
00:10:29,299 --> 00:10:32,620
值得一提的是，

150
00:10:32,620 --> 00:10:35,620
LangChain 的聊天模型接口

151
00:10:35,620 --> 00:10:38,620
提供了一些使用工具的常用方法。

152
00:10:38,620 --> 00:10:41,620
特别是这个绑定工具的方法，

153
00:10:41,620 --> 00:10:48,960
我们可以简单地传入一个工具列表，以及一些有用的参数。

154
00:10:48,960 --> 00:10:51,960
所以这个“工具选择”参数意味着模型被强制要求

155
00:10:51,960 --> 00:10:54,960
调用它拥有的任何可用工具。

156
00:10:54,960 --> 00:10:58,889
所以它总得调用工具。

157
00:10:58,889 --> 00:11:03,889
并行工具调用只是强制模型一次调用一个工具。

158
00:11:03,889 --> 00:11:06,889
有时模型可以一次调用多个工具，

159
00:11:06,889 --> 00:11:08,889
我们能控制。

160
00:11:08,889 --> 00:11:12,340
所以我们用工具定义模型。

161
00:11:12,340 --> 00:11:14,340
我们像以前一样调用它。

162
00:11:14,340 --> 00:11:20,370
在这种情况下，我们用一条与它所拥有的工具相关的消息来调用它，

163
00:11:20,370 --> 00:11:25,620
我们可以看到工具调用本身包含了所需的参数，

164
00:11:25,620 --> 00:11:30,909
以便实际运行该工具来处理内容。

165
00:11:30,909 --> 00:11:35,909
我们可以将这些参数直接传递给我们的工具，比如“发送邮件”，然后运行它，

166
00:11:35,909 --> 00:11:38,909
然后我们就能看到工具已执行。

167
00:11:38,909 --> 00:11:41,909
所以这是一个非常重要的概念。

168
00:11:41,909 --> 00:11:44,070
你可以把工具绑定到大模型。

169
00:11:44,070 --> 00:11:46,070
大模型可以调用工具。

170
00:11:46,070 --> 00:11:50,070
调用工具，就是大模型会生成结构化的参数输出。

171
00:11:50,070 --> 00:11:52,070
必须实际运行这个工具，

172
00:11:52,070 --> 00:11:55,070
然后这个工具就可以独立运行。

173
00:11:55,070 --> 00:11:58,070
这确实是构建智能体的基础组件。

174
00:11:58,070 --> 00:12:03,070
我们在上面看到的说明了我们之前看到的这个简单流程。

175
00:12:03,070 --> 00:12:07,649
我们将一个发送邮件工具绑定到一个大型语言模型，

176
00:12:07,649 --> 00:12:12,649
并强制它在回复邮件或请求时，调用该工具。

177
00:12:12,649 --> 00:12:17,779
正如我们讨论的，工作流和代理都由此延伸。

178
00:12:17,779 --> 00:12:23,779
对于工作流，我们可以在预定义的代码路径中嵌入大型语言模型调用。

179
00:12:23,779 --> 00:12:28,779
如我们所见，在调用大型语言模型之前，我们有一个路由器来处理邮件工具。

180
00:12:28,779 --> 00:12:31,779
代理只是在此基础上更进一步，

181
00:12:31,779 --> 00:12:35,779
让大型语言模型能循环、顺序地调用工具。

182
00:12:35,779 --> 00:12:39,779
现在，LandGraph 是所有工作流或代理的基础，

183
00:12:39,779 --> 00:12:44,779
它提供了一些特定的优势，我们现在将通过代码和一些简单的例子来演示。

184
00:12:44,779 --> 00:12:46,779
第一个优势是可控性。

185
00:12:46,779 --> 00:12:50,970
它让定义或组合代理和工作流变得非常容易。

186
00:12:50,970 --> 00:12:52,970
第二个好处是持久性。

187
00:12:52,970 --> 00:12:55,970
它提供了一种持久化图状态的方法，

188
00:12:55,970 --> 00:12:59,970
这使得内存和人工循环都成为可能，我们将会看到。

189
00:12:59,970 --> 00:13:04,029
它为测试、调试和部署应用程序提供了一个简单的入门途径。

190
00:13:04,029 --> 00:13:06,029
现在我们先来谈谈控制。

191
00:13:06,029 --> 00:13:09,029
LangGraph能让你把应用定义成图，

192
00:13:09,029 --> 00:13:13,029
你只需指定三样重要的东西。

193
00:13:13,029 --> 00:13:17,059
状态，也就是你想在应用中追踪的信息，

194
00:13:18,059 --> 00:13:22,059
节点，你希望如何在应用中更新状态，

195
00:13:22,059 --> 00:13:26,509
以及边，你希望如何连接这些节点。

196
00:13:26,509 --> 00:13:29,509
现在我们用状态图类初始化一个线图，

197
00:13:29,509 --> 00:13:32,769
然后传入一个状态对象。

198
00:13:32,769 --> 00:13:37,769
状态对象基本上是我们在应用过程中想要追踪的信息的模式。

199
00:13:37,769 --> 00:13:41,500
定义模式有几种选择。

200
00:13:41,500 --> 00:13:45,889
例如，类型字典很快，

201
00:13:45,889 --> 00:13:49,019
但它们不支持默认值。

202
00:13:49,019 --> 00:13:54,750
数据类其实很好用，因为它们支持默认值。

203
00:13:54,750 --> 00:14:00,039
Padantic会慢一点，但支持类型验证。

204
00:14:00,039 --> 00:14:04,620
所以你可以选择适合你应用的模式。

205
00:14:04,620 --> 00:14:06,620
这个简单例子，我们就用类型字典。

206
00:14:06,620 --> 00:14:09,620
大家可以看到，我在这里定义了我的状态模式。

207
00:14:09,620 --> 00:14:14,129
它只有两个键，request 和 email，都是字符串。

208
00:14:14,129 --> 00:14:18,289
然后我用我的模式初始化了我的状态图。

209
00:14:18,289 --> 00:14:21,860
现在我们来看看之前做的。

210
00:14:21,860 --> 00:14:24,860
我们用输入请求调用我们的工具模型。

211
00:14:24,860 --> 00:14:26,860
我们获取参数，然后称之为工具。

212
00:14:26,860 --> 00:14:29,860
我们可以把它都放到图中的一个节点里，

213
00:14:29,860 --> 00:14:32,860
你会发现这有两件有趣的事。

214
00:14:32,860 --> 00:14:36,860
第一，这个节点接收我们的状态对象。

215
00:14:36,860 --> 00:14:39,860
记住，我们之前定义过一个自然语言字典。

216
00:14:39,860 --> 00:14:43,860
我们可以从字典中提取任何想要的键，并加以利用。

217
00:14:43,860 --> 00:14:46,990
第二点是，它会返回一个字典。

218
00:14:46,990 --> 00:14:51,470
这个返回值基本上是在更新我们的状态。

219
00:14:51,470 --> 00:14:55,470
默认情况下，当我们从一个节点返回时，

220
00:14:55,470 --> 00:14:59,659
它会覆盖我们状态中特定的键，

221
00:14:59,659 --> 00:15:02,659
但当我们定义状态对象时，

222
00:15:02,659 --> 00:15:05,659
有些方法可以自定义它，

223
00:15:05,659 --> 00:15:09,080
比如追加，我们稍后会讲到。

224
00:15:09,080 --> 00:15:14,659
不过，在这个简单的例子中，我们将把我们的模型称为“工具”。

225
00:15:14,659 --> 00:15:16,659
它将生成一个工具调用。

226
00:15:16,659 --> 00:15:19,659
然后我们把这些参数传给邮件工具。

227
00:15:19,659 --> 00:15:26,909
我们可以发送邮件，然后用输出更新或覆盖状态键邮件。

228
00:15:26,909 --> 00:15:33,980
现在我们可以通过向图中添加节点和边来指定控制流。

229
00:15:33,980 --> 00:15:37,039
我们将添加单个节点，即邮件节点，

230
00:15:37,039 --> 00:15:42,580
并从两个边缘开始，转到该节点，

231
00:15:42,580 --> 00:15:47,649
从那个节点开始，走到终点，最后编译。

232
00:15:47,649 --> 00:15:51,649
完成这些后，我们就能很轻松地运行图了

233
00:15:51,649 --> 00:15:56,649
只需调用invoke，就能给状态传入初始值。

234
00:15:56,649 --> 00:16:01,649
这里，我们用请求初始化图，

235
00:16:01,649 --> 00:16:08,970
然后我们看到工具调用的输出被写入了状态中的邮件。

236
00:16:08,970 --> 00:16:11,970
状态字典已返回。

237
00:16:11,970 --> 00:16:14,320
我们运行图。

238
00:16:14,320 --> 00:16:19,320
在上述情况中，我们很简单地从边缘开始，

239
00:16:19,320 --> 00:16:23,450
到达我们的单一节点，然后从单一节点到结束。

240
00:16:23,450 --> 00:16:27,450
我们也可以使用条件边缘进行条件路由。

241
00:16:27,450 --> 00:16:30,019
我来举个例子。

242
00:16:30,019 --> 00:16:35,019
现在我们把图分成两个节点，调用大型语言模型，

243
00:16:35,019 --> 00:16:37,309
然后运行工具。

244
00:16:37,309 --> 00:16:40,409
现在我们可以添加一个条件边。

245
00:16:40,409 --> 00:16:45,409
它会查看是否单独调用了工具，

246
00:16:45,409 --> 00:16:49,789
如果是，就运行工具，否则不发送。

247
00:16:49,789 --> 00:16:52,789
这是我们构建代理时常做的事。

248
00:16:52,789 --> 00:16:56,950
我们用条件路由作为终止条件。

249
00:16:56,950 --> 00:16:59,950
如果代理在调用工具，我们就运行它。

250
00:16:59,950 --> 00:17:02,950
如果不是，我们就结束并退出代理循环。

251
00:17:02,950 --> 00:17:05,950
这点非常有用

252
00:17:05,950 --> 00:17:08,950
接下来看些有趣的东西

253
00:17:08,950 --> 00:17:13,109
这次我用消息状态初始化图表

254
00:17:13,109 --> 00:17:16,109
这是图表里预设的状态对象

255
00:17:16,109 --> 00:17:18,109
也就是单个关键消息

256
00:17:18,109 --> 00:17:22,589
当我们更新它时，如你所见，

257
00:17:22,589 --> 00:17:26,779
它只是简单地附加到消息列表，

258
00:17:26,779 --> 00:17:28,779
而不是覆盖。

259
00:17:28,779 --> 00:17:31,980
这在你构建代理时也非常有用，

260
00:17:31,980 --> 00:17:34,980
因为你希望累积消息。

261
00:17:34,980 --> 00:17:39,259
在智能体工具调用轨迹的整个过程中。

262
00:17:39,259 --> 00:17:42,710
你会看到，它应该继续。

263
00:17:42,710 --> 00:17:46,710
我们所做的就是获取最后一条消息

264
00:17:46,710 --> 00:17:48,809
从消息列表中。

265
00:17:48,809 --> 00:17:53,259
我们检查它是否是工具调用。

266
00:17:53,259 --> 00:17:58,259
如果是，我们就返回下一个节点的名称，去运行工具。

267
00:17:58,259 --> 00:18:00,259
否则，就结束。

268
00:18:00,259 --> 00:18:02,609
你们会看到一个有趣的差异。

269
00:18:03,609 --> 00:18:05,609
对于条件边，

270
00:18:05,609 --> 00:18:09,609
你返回的是你想要访问的下一个节点的名称。

271
00:18:09,609 --> 00:18:11,769
但有了节点，

272
00:18:11,769 --> 00:18:14,769
你就能更新状态。

273
00:18:14,769 --> 00:18:17,769
我们来编译一下，展示图表。

274
00:18:17,769 --> 00:18:20,769
现在我们开始，调用模型。

275
00:18:20,769 --> 00:18:23,769
根据模型是否喜欢工具调用，

276
00:18:23,769 --> 00:18:25,769
我们会运行工具与否。

277
00:18:25,769 --> 00:18:28,119
我们来试试看。

278
00:18:28,119 --> 00:18:29,119
好了。

279
00:18:29,119 --> 00:18:32,119
我们传入输入信息。

280
00:18:32,119 --> 00:18:34,180
模型会调用工具。

281
00:18:34,180 --> 00:18:37,180
然后我们连接到运行工具节点。

282
00:18:37,180 --> 00:18:40,250
工具就会像这样运行。

283
00:18:40,250 --> 00:18:43,250
仅用这些本地组件，

284
00:18:43,250 --> 00:18:45,250
就能构建出许多不同的东西。

285
00:18:45,250 --> 00:18:48,470
因为代理很常见，

286
00:18:48,470 --> 00:18:50,470
我们为此预设了一个抽象层，

287
00:18:50,470 --> 00:18:53,599
也就是我在这里展示的“创建React代理”。

288
00:18:53,599 --> 00:18:56,599
现在，对于这个代理抽象层，

289
00:18:56,599 --> 00:18:59,599
我们只需传入模型、工具列表，

290
00:18:59,599 --> 00:19:01,599
以及一个系统提示。

291
00:19:01,599 --> 00:19:03,599
我们像之前一样运行代理，

292
00:19:03,599 --> 00:19:05,599
传入消息。

293
00:19:05,599 --> 00:19:10,920
我们可以看到模型在这种情况下调用了工具。

294
00:19:10,920 --> 00:19:12,920
工具开始运行。

295
00:19:12,920 --> 00:19:14,920
现在，这里有个小区别

296
00:19:14,920 --> 00:19:15,920
我们之前看到的亲戚。

297
00:19:15,920 --> 00:19:18,920
记住，在工具运行后，我们只是结束。

298
00:19:18,920 --> 00:19:22,140
但正如所讨论的，对于代理，

299
00:19:22,140 --> 00:19:25,140
工具调用会返回给大型语言模型。

300
00:19:25,140 --> 00:19:27,529
所以发生的情况是，

301
00:19:27,529 --> 00:19:29,529
模型会看到这个工具调用

302
00:19:29,529 --> 00:19:34,619
然后给我们一个响应，指出调用的工具

303
00:19:34,619 --> 00:19:37,750
并且不再调用任何其他工具。

304
00:19:37,750 --> 00:19:41,359
这样就退出了工具调用循环

305
00:19:41,359 --> 00:19:43,460
智能体也就结束了。

306
00:19:43,460 --> 00:19:46,710
我们已经了解了LLM图的基本组成部分。

307
00:19:46,710 --> 00:19:49,869
我们还将代理抽象引入了LLM图。

308
00:19:49,869 --> 00:19:51,869
构建代理时，一个非常重要的点

309
00:19:51,869 --> 00:19:54,869
以及工作流（我们稍后会详细介绍），

310
00:19:54,869 --> 00:19:56,869
是持久化的概念。

311
00:19:56,869 --> 00:19:58,970
让智能体在执行

312
00:19:58,970 --> 00:20:02,160
耗时任务时暂停，会非常有用。

313
00:20:02,160 --> 00:20:04,160
Minecraft 有内置的持久层

314
00:20:04,160 --> 00:20:07,259
可以实现此功能，通过检查点实现。

315
00:20:07,259 --> 00:20:10,289
现在，在每个节点之后，

316
00:20:10,289 --> 00:20:13,450
检查点会保存图的状态。

317
00:20:13,450 --> 00:20:15,450
所以如果你暂停图，

318
00:20:15,450 --> 00:20:17,450
它的状态就会被保存下来，

319
00:20:17,450 --> 00:20:19,450
方便你之后恢复。

320
00:20:19,450 --> 00:20:21,450
现在我们来看个例子。

321
00:20:21,450 --> 00:20:24,859
我可以把那个创建React应用的抽象

322
00:20:24,859 --> 00:20:26,930
传递给一个检查点。

323
00:20:26,930 --> 00:20:30,220
我会问一些关于写邮件的好习惯。

324
00:20:30,220 --> 00:20:32,410
写邮件的好习惯。

325
00:20:32,410 --> 00:20:33,410
现在有了检查点，

326
00:20:33,410 --> 00:20:36,410
你会看到我需要传入一个线程ID。

327
00:20:36,410 --> 00:20:39,410
这基本上把检查点归类到一起，

328
00:20:39,410 --> 00:20:41,410
这样我以后可以引用它们。

329
00:20:41,410 --> 00:20:42,410
我们的代理运行了。

330
00:20:42,410 --> 00:20:44,440
真正好的是，

331
00:20:44,440 --> 00:20:47,470
我们可以获取智能体的当前状态，

332
00:20:47,470 --> 00:20:50,470
只需传入线程。

333
00:20:50,470 --> 00:20:53,700
我们会调用 agent.getState。

334
00:20:53,700 --> 00:20:55,700
然后我们可以提取

335
00:20:55,700 --> 00:20:58,700
智能体当前状态中的所有消息。

336
00:20:58,700 --> 00:21:00,700
现在我们看到，我们只有输入

337
00:21:00,700 --> 00:21:05,200
和智能体的回复。

338
00:21:05,200 --> 00:21:08,519
现在我们继续对话。

339
00:21:08,519 --> 00:21:11,650
我只需要重新调用我的智能体

340
00:21:11,650 --> 00:21:12,650
然后我会说，太棒了，

341
00:21:12,650 --> 00:21:14,650
我们用第三课

342
00:21:14,650 --> 00:21:18,650
简洁地回复老板

343
00:21:18,650 --> 00:21:21,779
我可以直接传入配置

344
00:21:21,779 --> 00:21:24,900
该配置表示线程

345
00:21:24,900 --> 00:21:28,160
如果我能运行，我们就能看到代理

346
00:21:28,160 --> 00:21:32,319
可以访问之前的消息

347
00:21:32,319 --> 00:21:34,319
因为它们都保存在对话串中

348
00:21:34,319 --> 00:21:36,319
然后它会生成一封邮件。

349
00:21:36,319 --> 00:21:39,799
我就可以继续操作

350
00:21:39,799 --> 00:21:41,799
传入那个对话串ID

351
00:21:41,799 --> 00:21:43,799
然后说我喜欢这个。

352
00:21:43,799 --> 00:21:46,089
你去写这封邮件。

353
00:21:46,089 --> 00:21:48,089
现在你可以看到它会

354
00:21:48,089 --> 00:21:50,339
调用工具。

355
00:21:50,339 --> 00:21:52,339
工具已执行。

356
00:21:52,339 --> 00:21:56,109
邮件已发送。

357
00:21:56,109 --> 00:21:59,529
另外，检查点

358
00:21:59,529 --> 00:22:01,529
还有一个很强大的功能

359
00:22:01,529 --> 00:22:02,529
就是我们可以在特定节点

360
00:22:02,529 --> 00:22:05,849
中断图表。

361
00:22:05,849 --> 00:22:07,849
这是一个非常简单的图表示例

362
00:22:07,849 --> 00:22:08,849
我想在这里中断

363
00:22:08,849 --> 00:22:10,849
在特定节点处进行人工反馈

364
00:22:10,849 --> 00:22:14,069
以收集用户的反馈。

365
00:22:14,069 --> 00:22:18,200
你所要做的就是添加这个中断对象

366
00:22:18,200 --> 00:22:20,200
到节点

367
00:22:20,200 --> 00:22:23,619
用检查点编译图。

368
00:22:23,619 --> 00:22:26,000
我们能看到图的流程。

369
00:22:26,000 --> 00:22:28,000
我们会像之前一样创建线程。

370
00:22:28,000 --> 00:22:30,000
我们会运行一个图。

371
00:22:30,000 --> 00:22:33,130
我会简单地将更新

372
00:22:33,130 --> 00:22:35,130
推送到图中运行的每个节点

373
00:22:35,130 --> 00:22:38,130
通过指示流模式更新。

374
00:22:38,130 --> 00:22:40,130
有趣的是

375
00:22:40,130 --> 00:22:43,130
当我们触及人工反馈节点时，

376
00:22:43,130 --> 00:22:46,130
图表发出中断

377
00:22:46,130 --> 00:22:49,130
请提供反馈

378
00:22:49,130 --> 00:22:51,130
这正是我们传入的

379
00:22:51,130 --> 00:22:53,420
中断对象

380
00:22:53,420 --> 00:22:54,420
现在要恢复

381
00:22:54,420 --> 00:22:56,420
你要做的就是使用这个命令对象

382
00:22:56,420 --> 00:22:58,420
在折线图里

383
00:22:58,420 --> 00:23:01,420
传入我想要的人工反馈。

384
00:23:01,420 --> 00:23:03,579
现在要从中断中恢复，

385
00:23:03,579 --> 00:23:05,579
我们只需再次调用图表

386
00:23:05,579 --> 00:23:06,579
使用命令对象

387
00:23:06,579 --> 00:23:08,990
然后我们传入resume。

388
00:23:08,990 --> 00:23:11,339
我们可以直接传入一个字符串

389
00:23:11,339 --> 00:23:13,339
我们的反馈就会传递给

390
00:23:13,339 --> 00:23:14,339
我们的节点

391
00:23:14,339 --> 00:23:16,339
并写入到我们的状态中

392
00:23:16,339 --> 00:23:19,400
作为用户反馈。

393
00:23:19,400 --> 00:23:20,400
所以我们无论传入什么

394
00:23:20,400 --> 00:23:22,460
到这个resume

395
00:23:22,460 --> 00:23:24,460
和中断后的命令

396
00:23:24,460 --> 00:23:27,910
直接传入我们的图表。

397
00:23:27,910 --> 00:23:30,329
我们现在能看到的是

398
00:23:30,329 --> 00:23:33,329
我们收到反馈的地方，

399
00:23:33,329 --> 00:23:35,900
将其运行到状态。

400
00:23:35,900 --> 00:23:39,099
现在，因为我设置了这两个环境变量，

401
00:23:39,099 --> 00:23:41,130
我们刚才做的一切

402
00:23:41,130 --> 00:23:43,130
都记录在 Langsmith 上。

403
00:23:43,130 --> 00:23:45,640
我可以查看 Langsmith 追踪

404
00:23:45,640 --> 00:23:47,640
任何上述执行过程。

405
00:23:47,640 --> 00:23:51,019
这是一个查看我们代理的例子

406
00:23:51,019 --> 00:23:53,019
我们在Langsmith里看到

407
00:23:53,019 --> 00:23:55,089
这是我们智能体的图节点。

408
00:23:55,089 --> 00:23:57,309
可以打开它。

409
00:23:57,309 --> 00:24:00,309
这显示了具体的模型调用。

410
00:24:00,309 --> 00:24:01,309
打开它。

411
00:24:01,309 --> 00:24:04,789
你可以看到这是绑定工具。

412
00:24:04,789 --> 00:24:08,079
我们称之为“正确邮件工具”。

413
00:24:08,079 --> 00:24:10,079
这是信息列表，

414
00:24:10,079 --> 00:24:12,559
已发送和已接收。

415
00:24:12,559 --> 00:24:14,559
然后这是最终的工具调用。

416
00:24:14,559 --> 00:24:16,779
然后我们来到工具节点，

417
00:24:16,779 --> 00:24:17,779
打开它，

418
00:24:17,779 --> 00:24:19,779
你会看到这是工具的调用，

419
00:24:19,779 --> 00:24:21,849
以及我们工具的输出，

420
00:24:21,849 --> 00:24:23,849
作为一条工具消息。

421
00:24:23,849 --> 00:24:26,329
最后，它又回到了我们的代理。

422
00:24:26,329 --> 00:24:28,329
我们可以看到那个调用模型，

423
00:24:28,329 --> 00:24:30,519
节点，

424
00:24:30,519 --> 00:24:32,519
我们可以专门看看L和调用，

425
00:24:32,519 --> 00:24:34,519
看看那个节点工具调用

426
00:24:34,519 --> 00:24:37,519
模块会响应

427
00:24:37,519 --> 00:24:39,619
一条IAM消息

428
00:24:39,619 --> 00:24:41,940
说邮件已发送。

429
00:24:41,940 --> 00:24:44,940
Langsmith能很好地帮你分析追踪记录

430
00:24:44,940 --> 00:24:48,190
它还会为你记录有用的元数据

431
00:24:48,190 --> 00:24:50,190
就像你在这里看到的。

432
00:24:50,190 --> 00:24:52,349
除了Langsmith，

433
00:24:52,349 --> 00:24:54,480
我还想谈谈Langchain生态系统中

434
00:24:54,480 --> 00:24:57,480
另一个重要且实用的功能，

435
00:24:57,480 --> 00:25:00,700
它能让我们部署代理。

436
00:25:00,700 --> 00:25:02,700
或工作流。

437
00:25:02,700 --> 00:25:04,700
这就是Langarth平台。

438
00:25:04,700 --> 00:25:07,279
我们在笔记本里做的所有事

439
00:25:07,279 --> 00:25:09,279
都很适合测试

440
00:25:09,279 --> 00:25:12,470
和快速原型开发。

441
00:25:12,470 --> 00:25:14,470
但如果我想把这些代码

442
00:25:14,470 --> 00:25:17,470
变成可部署的应用呢？

443
00:25:17,470 --> 00:25:19,789
这就是Langarth平台的作用。

444
00:25:19,789 --> 00:25:22,109
它能让你轻松地

445
00:25:22,109 --> 00:25:24,430
从工作流代理到

446
00:25:25,430 --> 00:25:27,880
一个可部署的服务器

447
00:25:27,880 --> 00:25:30,880
通过API与图数据交互。

448
00:25:30,880 --> 00:25:32,200
此外，

449
00:25:32,200 --> 00:25:34,200
Langarth平台还提供了

450
00:25:34,200 --> 00:25:36,200
一个交互式IDE，名为Langarth Studio。

451
00:25:36,200 --> 00:25:39,200
这是一个非常有用的方法，可以进一步检查

452
00:25:39,200 --> 00:25:41,460
和调试我们的代理。

453
00:25:41,460 --> 00:25:43,809
要使用Langsmith平台，

454
00:25:43,809 --> 00:25:45,809
我们需要做的就是确保我们的项目

455
00:25:45,809 --> 00:25:48,059
具有如图所示的结构。

456
00:25:48,059 --> 00:25:50,059
最重要的是

457
00:25:50,059 --> 00:25:52,160
这个Langarth.json文件。

458
00:25:52,160 --> 00:25:54,160
它只是一个配置文件。

459
00:25:54,160 --> 00:25:56,319
在这个仓库的根目录里，

460
00:25:56,319 --> 00:25:58,319
它定义了依赖关系、图表，

461
00:25:58,319 --> 00:25:59,319
环境变量，

462
00:25:59,319 --> 00:26:01,319
以及启动

463
00:26:01,319 --> 00:26:03,319
Langarth服务器所需的其他东西。

464
00:26:03,319 --> 00:26:05,319
这是一个相当简单的配置。

465
00:26:05,319 --> 00:26:07,319
配置主要包含

466
00:26:07,319 --> 00:26:10,349
只是图的名称

467
00:26:10,349 --> 00:26:12,509
和路径。

468
00:26:12,509 --> 00:26:13,509
举个例子，

469
00:26:13,509 --> 00:26:15,670
在一个仓库里，

470
00:26:15,670 --> 00:26:16,670
在这个目录下，

471
00:26:16,670 --> 00:26:19,859
我们有个文件叫Langarth 101.py，

472
00:26:19,859 --> 00:26:21,859
里面包含了一些代码

473
00:26:21,859 --> 00:26:24,410
是我们刚在这个notebook里做的原型

474
00:26:24,410 --> 00:26:26,789
作为可部署的图。

475
00:26:26,789 --> 00:26:27,789
现在用Langarth平台，

476
00:26:27,789 --> 00:26:29,789
有几种不同的部署方式。

477
00:26:29,789 --> 00:26:31,890
我想确保我们都清楚。

478
00:26:31,890 --> 00:26:34,890
最简单、免费的方式是本地部署，

479
00:26:34,890 --> 00:26:36,890
它在你的本地机器上运行，

480
00:26:36,890 --> 00:26:38,890
我只需要在这个目录的根目录下

481
00:26:38,890 --> 00:26:41,210
是在Langarth开发版上运行的。

482
00:26:41,210 --> 00:26:43,210
它仍然具有持久性，

483
00:26:43,210 --> 00:26:46,529
检查点应该写入本地文件系统。

484
00:26:46,529 --> 00:26:49,529
现在，还有很多自托管的部署选项，

485
00:26:49,529 --> 00:26:51,529
也有托管部署，

486
00:26:51,529 --> 00:26:53,750
使用Postgres，

487
00:26:53,750 --> 00:26:55,069
进行持久化。

488
00:26:55,069 --> 00:26:57,069
我们就从仓库根目录

489
00:26:57,069 --> 00:26:59,140
运行Langarth dev，

490
00:26:59,140 --> 00:27:00,140
看看会发生什么。

491
00:27:00,140 --> 00:27:02,549
运行Langarth开发版

492
00:27:02,549 --> 00:27:04,549
浏览器就会弹出这个界面

493
00:27:04,549 --> 00:27:06,970
这是Langarth工作室

494
00:27:06,970 --> 00:27:08,970
你可以浏览各种图表

495
00:27:08,970 --> 00:27:10,970
它们都存在于repo中

496
00:27:10,970 --> 00:27:13,289
点击“朗加斯101”。

497
00:27:13,289 --> 00:27:16,289
这是我们在笔记本中构建的图表之一。

498
00:27:16,289 --> 00:27:18,670
我们可以打开这个输入窗格，

499
00:27:18,670 --> 00:27:19,670
打开消息，

500
00:27:19,670 --> 00:27:20,670
传入一条消息，

501
00:27:20,670 --> 00:27:21,670
提交，

502
00:27:21,670 --> 00:27:23,769
就能看到图的状态

503
00:27:23,769 --> 00:27:25,900
在这里，

504
00:27:25,900 --> 00:27:27,900
它显示了图中的每个节点，

505
00:27:27,900 --> 00:27:28,900
以及状态更新，

506
00:27:28,900 --> 00:27:31,119
在那个特定节点。

507
00:27:31,119 --> 00:27:34,440
你也可以点击“打开运行Langsmiths”，

508
00:27:34,440 --> 00:27:38,019
查看轨迹，了解语言模型调用，

509
00:27:38,019 --> 00:27:39,019
在调用语言模型节点中，

510
00:27:39,019 --> 00:27:42,019
以及在运行工具节点中的工具执行。

511
00:27:42,019 --> 00:27:45,039
另外，我还想指出一点

512
00:27:45,039 --> 00:27:48,809
你可以看到本地部署的API文档，

513
00:27:48,809 --> 00:27:49,809
就在这里，

514
00:27:49,809 --> 00:27:52,420
你可以浏览

515
00:27:52,420 --> 00:27:54,420
查看所有可用的端点。

516
00:27:54,420 --> 00:27:56,420
我们已经讲了这门课的

517
00:27:56,420 --> 00:27:58,480
很多基础知识。

518
00:27:58,480 --> 00:28:00,740
我们讲了Langchain

519
00:28:00,740 --> 00:28:01,740
和一些有用的接口，

520
00:28:01,740 --> 00:28:03,740
比如init chat model，

521
00:28:03,740 --> 00:28:05,059
工具

522
00:28:05,059 --> 00:28:07,150
以及使用聊天模型。

523
00:28:07,150 --> 00:28:10,150
我们讨论了LangChain的基础

524
00:28:10,150 --> 00:28:12,150
以及代理和工作流的区别。

525
00:28:12,150 --> 00:28:14,150
我们还展示了LangSmith，

526
00:28:14,150 --> 00:28:16,150
以及LangChain部署

527
00:28:16,150 --> 00:28:18,150
和LangChain Studio。

528
00:28:18,150 --> 00:28:20,150
我们讲了持久化和中断。

529
00:28:20,150 --> 00:28:24,410
我们还讲了Langsmith和可观测性，

530
00:28:24,410 --> 00:28:26,410
以及LangChain平台，

531
00:28:26,410 --> 00:28:28,410
展示本地部署，

532
00:28:28,410 --> 00:28:30,569
还有Langarth Studio。

533
00:28:30,569 --> 00:28:31,569
这些都是你接下来课程中

534
00:28:31,569 --> 00:28:34,569
需要用到的所有基础知识。
