# 批次大小优化指南

## 问题背景

在使用SRT翻译Agent时，您可能遇到以下问题：
1. **LangGraph递归限制**：`Recursion limit of 25 reached without hitting a stop condition`
2. **批次大小配置**：如何优化翻译批次大小以平衡速度和质量

## 解决方案

### 1. LangGraph递归限制问题

#### 问题原因
LangGraph默认递归限制为25步，但我们的翻译工作流可能需要更多步骤来完成批量翻译。

#### 解决方法
我们已经在代码中添加了 `recursion_limit: 100` 配置：

```python
# 在 srt_translator_agent.py 中
result = self.app.invoke(
    initial_state,
    config={
        "recursion_limit": 100,  # 增加递归限制
        "configurable": {"thread_id": f"translation_{int(time.time())}"}
    }
)
```

#### 官方文档参考
根据LangGraph官方文档：
- 默认递归限制：25步
- 推荐设置：50-200步
- 设置方法：`config={"recursion_limit": 100}`

### 2. 批次大小优化

#### 批次大小参数说明

| 批次大小 | 优势 | 劣势 | 适用场景 |
|---------|------|------|----------|
| **1-2** | 最高质量，最稳定 | 速度最慢，API调用多 | 重要内容，高质量要求 |
| **3-5** | 平衡质量和速度 | 中等速度 | **日常使用推荐** |
| **6-10** | 速度快，成本低 | 质量可能下降 | 批量处理，快速预览 |
| **10+** | 最快速度 | 质量不稳定，易超时 | 不推荐 |

#### 配置方法

##### 1. 在translation_example.py中配置
```python
# 基础翻译 - 小批量
agent = SRTTranslatorAgent(batch_size=3)

# 高质量翻译 - 最小批量
agent = SRTTranslatorAgent(
    llm_model="gpt-4",
    batch_size=2
)

# 批量处理 - 中等批量
agent = SRTTranslatorAgent(batch_size=5)
```

##### 2. 在main.py中配置
```bash
# 完整工作流 - 指定批次大小
uv run python main.py video.mp4 --mode full -l en -s 英文 -t 中文 -b 3

# 仅翻译 - 高质量小批量
uv run python main.py subtitle.srt --mode translate -s 英文 -t 中文 -b 2

# 快速处理 - 大批量
uv run python main.py subtitle.srt --mode translate -s 英文 -t 中文 -b 8
```

##### 3. 在srt_translator_agent.py中配置
```bash
# 命令行直接指定
uv run python srt_translator_agent.py input.srt -s 英文 -t 中文 -b 3
```

#### 推荐配置

##### 内容质量优先
```python
agent = SRTTranslatorAgent(
    llm_model="gpt-4",
    batch_size=2
)
```

##### 平衡质量和速度（推荐）
```python
agent = SRTTranslatorAgent(
    llm_model="gpt-4o-mini",
    batch_size=3
)
```

##### 速度优先
```python
agent = SRTTranslatorAgent(
    llm_model="gpt-4o-mini", 
    batch_size=5
)
```

## 故障排除

### 问题1: 递归限制错误
```
❌ 翻译失败: Recursion limit of 25 reached without hitting a stop condition
```

**解决方案**：
1. 确保使用最新代码（已包含递归限制修复）
2. 如果仍有问题，可以手动增加限制：

```python
# 在调用时增加递归限制
config = {
    "recursion_limit": 200,  # 进一步增加限制
    "configurable": {"thread_id": "test"}
}
```

### 问题2: 翻译超时或失败
```
❌ 批量翻译失败: timeout/connection error
```

**解决方案**：
1. 减少批次大小：`batch_size=2`
2. 检查网络连接
3. 验证API密钥和代理配置

### 问题3: 翻译质量不满意
```
⚠️ 翻译结果质量较低
```

**解决方案**：
1. 使用更高级模型：`llm_model="gpt-4"`
2. 减少批次大小：`batch_size=2`
3. 检查源语言和目标语言设置

## 性能测试

### 测试不同批次大小的效果
```bash
# 测试小批量 (高质量)
uv run python main.py test.srt --mode translate -s 英文 -t 中文 -b 2

# 测试中批量 (平衡)
uv run python main.py test.srt --mode translate -s 英文 -t 中文 -b 5

# 测试大批量 (快速)
uv run python main.py test.srt --mode translate -s 英文 -t 中文 -b 10
```

### 验证配置
```bash
# 空运行验证
uv run python main.py test.srt --mode translate -s 英文 -t 中文 -b 3 --dry-run
```

## 环境变量配置

确保正确设置了代理提供商配置：

```bash
# 设置环境变量
export OPENAI_API_KEY=your_api_key
export MODEL_BASE_URL=https://your.proxy.com/v1
export MODEL_NAME=gpt-4o-mini
```

## 最佳实践

1. **首次使用**：从 `batch_size=3` 开始测试
2. **重要内容**：使用 `batch_size=2` + `gpt-4`
3. **批量处理**：使用 `batch_size=5` + `gpt-4o-mini`
4. **网络不稳定**：减少到 `batch_size=2`
5. **内存限制**：减少到 `batch_size=1`

## 监控和调优

### 实时监控
- 观察日志中的批次翻译进度
- 注意API调用频率和响应时间
- 监控内存使用情况

### 性能指标
- **翻译质量**：人工检查关键段落
- **处理速度**：记录完成时间
- **成功率**：监控失败的批次数量
- **成本效益**：平衡API调用次数和质量

通过合理配置批次大小和递归限制，您可以获得最佳的翻译效果和处理速度。 