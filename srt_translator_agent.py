#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SRTç¿»è¯‘Agent - åŸºäºLangGraph
å°†SRTå­—å¹•æ–‡ä»¶ç¿»è¯‘ä¸ºåŒè¯­å­—å¹•
"""

import os
import re
import time
import json
import argparse
from pathlib import Path
from datetime import datetime
from typing import TypedDict, List, Dict, Optional
from dataclasses import dataclass

# LangGraphç›¸å…³å¯¼å…¥
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver

# LangChainç›¸å…³å¯¼å…¥
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import HumanMessage, SystemMessage

import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

@dataclass
class SRTEntry:
    """SRTå­—å¹•æ¡ç›®"""
    index: int
    start_time: str
    end_time: str
    text: str
    translation: str = ""

class TranslationState(TypedDict):
    """ç¿»è¯‘AgentçŠ¶æ€"""
    input_file: str
    output_file: str
    source_lang: str
    target_lang: str
    entries: List[SRTEntry]
    current_index: int
    total_entries: int
    translation_progress: float
    errors: List[str]
    llm_model: str
    batch_size: int
    max_retries: int
    bilingual_content: str

class SRTTranslatorAgent:
    """åŸºäºLangGraphçš„SRTç¿»è¯‘Agent"""
    
    def __init__(self, 
                 llm_model: Optional[str] = None,
                 api_key: Optional[str] = None,
                 base_url: Optional[str] = None,
                 batch_size: int = 5,
                 max_retries: int = 3):
        """
        åˆå§‹åŒ–ç¿»è¯‘Agent
        
        Args:
            llm_model: ä½¿ç”¨çš„è¯­è¨€æ¨¡å‹ï¼ˆå¯é€šè¿‡MODEL_NAMEç¯å¢ƒå˜é‡è®¾ç½®ï¼‰
            api_key: APIå¯†é’¥ï¼ˆå¯é€šè¿‡OPENAI_API_KEYç¯å¢ƒå˜é‡è®¾ç½®ï¼‰
            base_url: APIåŸºç¡€URLï¼ˆå¯é€šè¿‡MODEL_BASE_URLç¯å¢ƒå˜é‡è®¾ç½®ï¼‰
            batch_size: æ‰¹é‡ç¿»è¯‘å¤§å°
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        """
        # ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        self.base_url = base_url or os.getenv("MODEL_BASE_URL")
        self.llm_model = llm_model or os.getenv("MODEL_NAME") or "gpt-4o-mini"
        
        self.batch_size = batch_size
        self.max_retries = max_retries
        
        # åˆå§‹åŒ–LLMå‚æ•°
        llm_kwargs = {
            "model": self.llm_model,
            "api_key": self.api_key,
            "temperature": 0.3
        }
        
        # å¦‚æœæœ‰base_urlé…ç½®ï¼Œæ·»åŠ åˆ°å‚æ•°ä¸­
        if self.base_url:
            llm_kwargs["base_url"] = self.base_url
        
        # åˆå§‹åŒ–LLM
        self.llm = ChatOpenAI(**llm_kwargs)
        
        # åˆå§‹åŒ–LangGraph
        self.workflow = self._build_workflow()
        self.checkpointer = MemorySaver()
        self.app = self.workflow.compile(checkpointer=self.checkpointer)
        
        logger.info(f"ğŸ¤– SRTç¿»è¯‘Agentå·²åˆå§‹åŒ–:")
        logger.info(f"   æ¨¡å‹: {llm_model}")
        logger.info(f"   æ‰¹é‡å¤§å°: {batch_size}")
        logger.info(f"   æœ€å¤§é‡è¯•: {max_retries}")
    
    def _build_workflow(self) -> StateGraph:
        """æ„å»ºLangGraphå·¥ä½œæµ"""
        workflow = StateGraph(TranslationState)
        
        # æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("parse_srt", self.parse_srt_node)
        workflow.add_node("translate_batch", self.translate_batch_node)
        workflow.add_node("validate_translation", self.validate_translation_node)
        workflow.add_node("generate_bilingual_srt", self.generate_bilingual_srt_node)
        workflow.add_node("save_result", self.save_result_node)
        
        # è®¾ç½®å…¥å£ç‚¹
        workflow.set_entry_point("parse_srt")
        
        # æ·»åŠ è¾¹
        workflow.add_edge("parse_srt", "translate_batch")
        workflow.add_conditional_edges(
            "translate_batch",
            self.should_continue_translation,
            {
                "continue": "translate_batch",
                "validate": "validate_translation"
            }
        )
        workflow.add_edge("validate_translation", "generate_bilingual_srt")
        workflow.add_edge("generate_bilingual_srt", "save_result")
        workflow.add_edge("save_result", END)
        
        return workflow
    
    def parse_srt_node(self, state: TranslationState) -> TranslationState:
        """è§£æSRTæ–‡ä»¶èŠ‚ç‚¹"""
        logger.info(f"ğŸ“– å¼€å§‹è§£æSRTæ–‡ä»¶: {state['input_file']}")
        
        try:
            entries = self._parse_srt_file(state['input_file'])
            state['entries'] = entries
            state['total_entries'] = len(entries)
            state['current_index'] = 0
            state['translation_progress'] = 0.0
            
            logger.info(f"âœ… SRTè§£æå®Œæˆï¼Œå…± {len(entries)} æ¡å­—å¹•")
            
        except Exception as e:
            error_msg = f"SRTæ–‡ä»¶è§£æå¤±è´¥: {e}"
            logger.error(error_msg)
            state['errors'].append(error_msg)
        
        return state
    
    def translate_batch_node(self, state: TranslationState) -> TranslationState:
        """æ‰¹é‡ç¿»è¯‘èŠ‚ç‚¹"""
        start_idx = state['current_index']
        end_idx = min(start_idx + state['batch_size'], state['total_entries'])
        
        logger.info(f"ğŸ”„ ç¿»è¯‘æ‰¹æ¬¡ {start_idx + 1}-{end_idx} / {state['total_entries']}")
        
        # å‡†å¤‡æ‰¹é‡ç¿»è¯‘
        batch_entries = state['entries'][start_idx:end_idx]
        texts_to_translate = [entry.text for entry in batch_entries]
        
        try:
            # æ‰§è¡Œæ‰¹é‡ç¿»è¯‘
            translations = self._batch_translate(
                texts_to_translate,
                state['source_lang'],
                state['target_lang']
            )
            
            # æ›´æ–°ç¿»è¯‘ç»“æœ
            for i, translation in enumerate(translations):
                state['entries'][start_idx + i].translation = translation
            
            # æ›´æ–°è¿›åº¦
            state['current_index'] = end_idx
            state['translation_progress'] = end_idx / state['total_entries']
            
            logger.info(f"âœ… æ‰¹æ¬¡ç¿»è¯‘å®Œæˆï¼Œè¿›åº¦: {state['translation_progress']:.1%}")
            
        except Exception as e:
            error_msg = f"æ‰¹é‡ç¿»è¯‘å¤±è´¥: {e}"
            logger.error(error_msg)
            state['errors'].append(error_msg)
        
        return state
    
    def should_continue_translation(self, state: TranslationState) -> str:
        """åˆ¤æ–­æ˜¯å¦ç»§ç»­ç¿»è¯‘"""
        if state['current_index'] < state['total_entries']:
            return "continue"
        else:
            return "validate"
    
    def validate_translation_node(self, state: TranslationState) -> TranslationState:
        """éªŒè¯ç¿»è¯‘è´¨é‡èŠ‚ç‚¹"""
        logger.info("ğŸ” éªŒè¯ç¿»è¯‘è´¨é‡...")
        
        empty_translations = 0
        for entry in state['entries']:
            if not entry.translation.strip():
                empty_translations += 1
        
        if empty_translations > 0:
            logger.warning(f"âš ï¸ å‘ç° {empty_translations} æ¡ç©ºç¿»è¯‘")
            state['errors'].append(f"å­˜åœ¨ {empty_translations} æ¡ç©ºç¿»è¯‘")
        else:
            logger.info("âœ… ç¿»è¯‘è´¨é‡éªŒè¯é€šè¿‡")
        
        return state
    
    def generate_bilingual_srt_node(self, state: TranslationState) -> TranslationState:
        """ç”ŸæˆåŒè¯­SRTèŠ‚ç‚¹"""
        logger.info("ğŸ“ ç”ŸæˆåŒè¯­SRTå†…å®¹...")
        
        try:
            bilingual_content = self._generate_bilingual_content(state['entries'])
            state['bilingual_content'] = bilingual_content
            logger.info("âœ… åŒè¯­SRTå†…å®¹ç”Ÿæˆå®Œæˆ")
            
        except Exception as e:
            error_msg = f"åŒè¯­SRTç”Ÿæˆå¤±è´¥: {e}"
            logger.error(error_msg)
            state['errors'].append(error_msg)
        
        return state
    
    def save_result_node(self, state: TranslationState) -> TranslationState:
        """ä¿å­˜ç»“æœèŠ‚ç‚¹"""
        logger.info(f"ğŸ’¾ ä¿å­˜åŒè¯­SRTæ–‡ä»¶: {state['output_file']}")
        
        try:
            with open(state['output_file'], 'w', encoding='utf-8') as f:
                f.write(state['bilingual_content'])
            
            logger.info(f"âœ… åŒè¯­SRTæ–‡ä»¶å·²ä¿å­˜: {state['output_file']}")
            
        except Exception as e:
            error_msg = f"æ–‡ä»¶ä¿å­˜å¤±è´¥: {e}"
            logger.error(error_msg)
            state['errors'].append(error_msg)
        
        return state
    
    def _parse_srt_file(self, file_path: str) -> List[SRTEntry]:
        """è§£æSRTæ–‡ä»¶"""
        entries = []
        
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # SRTæ ¼å¼æ­£åˆ™è¡¨è¾¾å¼
        pattern = r'(\d+)\n(\d{2}:\d{2}:\d{2},\d{3}) --> (\d{2}:\d{2}:\d{2},\d{3})\n(.*?)(?=\n\d+\n|\n*$)'
        matches = re.findall(pattern, content, re.DOTALL)
        
        for match in matches:
            index = int(match[0])
            start_time = match[1]
            end_time = match[2]
            text = match[3].strip().replace('\n', ' ')
            
            entries.append(SRTEntry(
                index=index,
                start_time=start_time,
                end_time=end_time,
                text=text
            ))
        
        return entries
    
    def _batch_translate(self, texts: List[str], source_lang: str, target_lang: str) -> List[str]:
        """æ‰¹é‡ç¿»è¯‘æ–‡æœ¬"""
        # åˆ›å»ºç¿»è¯‘æç¤ºæ¨¡æ¿
        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­—å¹•ç¿»è¯‘å¸ˆã€‚è¯·å°†ä»¥ä¸‹{source_lang}å­—å¹•ç¿»è¯‘ä¸º{target_lang}ã€‚

è¦æ±‚ï¼š
1. ä¿æŒåŸæ„å‡†ç¡®ï¼Œè¯­è¨€è‡ªç„¶æµç•…
2. é€‚åˆå£è¯­åŒ–è¡¨è¾¾
3. ä¿æŒç®€æ´ï¼Œé€‚åˆå­—å¹•æ˜¾ç¤º
4. ä¸“ä¸šæœ¯è¯­è¯·å‡†ç¡®ç¿»è¯‘
5. æ¯è¡Œç¿»è¯‘å¯¹åº”ä¸€è¡ŒåŸæ–‡

è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼Œæ¯è¡Œä¸€ä¸ªç¿»è¯‘ç»“æœï¼š
1. [ç¬¬ä¸€è¡Œç¿»è¯‘]
2. [ç¬¬äºŒè¡Œç¿»è¯‘]
...
"""
        
        # æ ¼å¼åŒ–è¾“å…¥æ–‡æœ¬
        numbered_texts = [f"{i+1}. {text}" for i, text in enumerate(texts)]
        user_input = "\n".join(numbered_texts)
        
        prompt = ChatPromptTemplate.from_messages([
            ("system", system_prompt),
            ("human", "{input}")
        ])
        
        # æ‰§è¡Œç¿»è¯‘
        chain = prompt | self.llm
        response = chain.invoke({"input": user_input})
        
        # è§£æç¿»è¯‘ç»“æœ
        response_content = str(response.content if hasattr(response, 'content') else response)
        translations = self._parse_translation_response(response_content, len(texts))
        
        return translations
    
    def _parse_translation_response(self, response: str, expected_count: int) -> List[str]:
        """è§£æç¿»è¯‘å“åº”"""
        lines = response.strip().split('\n')
        translations = []
        
        for line in lines:
            # ç§»é™¤åºå·
            cleaned = re.sub(r'^\d+\.\s*', '', line.strip())
            if cleaned:
                translations.append(cleaned)
        
        # ç¡®ä¿ç¿»è¯‘æ•°é‡æ­£ç¡®
        while len(translations) < expected_count:
            translations.append("[ç¿»è¯‘å¤±è´¥]")
        
        return translations[:expected_count]
    
    def _generate_bilingual_content(self, entries: List[SRTEntry]) -> str:
        """ç”ŸæˆåŒè¯­SRTå†…å®¹"""
        content_lines = []
        
        for entry in entries:
            content_lines.append(str(entry.index))
            content_lines.append(f"{entry.start_time} --> {entry.end_time}")
            content_lines.append(entry.text)
            content_lines.append(entry.translation)
            content_lines.append("")  # ç©ºè¡Œåˆ†éš”
        
        return "\n".join(content_lines)
    
    def translate_srt(self, 
                      input_file: str,
                      output_file: Optional[str] = None,
                      source_lang: str = "è‹±æ–‡",
                      target_lang: str = "ä¸­æ–‡") -> str:
        """
        ç¿»è¯‘SRTæ–‡ä»¶
        
        Args:
            input_file: è¾“å…¥SRTæ–‡ä»¶è·¯å¾„
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            source_lang: æºè¯­è¨€
            target_lang: ç›®æ ‡è¯­è¨€
        
        Returns:
            str: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
        if output_file is None:
            input_path = Path(input_file)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = str(input_path.parent / f"{input_path.stem}_bilingual_{timestamp}.srt")
        
        # åˆå§‹åŒ–çŠ¶æ€
        initial_state = TranslationState(
            input_file=input_file,
            output_file=str(output_file),
            source_lang=source_lang,
            target_lang=target_lang,
            entries=[],
            current_index=0,
            total_entries=0,
            translation_progress=0.0,
            errors=[],
            llm_model=self.llm_model,
            batch_size=self.batch_size,
            max_retries=self.max_retries,
            bilingual_content=""
        )
        
        # è¿è¡Œå·¥ä½œæµ
        logger.info(f"ğŸš€ å¼€å§‹ç¿»è¯‘SRTæ–‡ä»¶: {input_file}")
        logger.info(f"ğŸ“ æºè¯­è¨€: {source_lang} â†’ ç›®æ ‡è¯­è¨€: {target_lang}")
        
        try:
            # æ‰§è¡Œç¿»è¯‘å·¥ä½œæµ - å¢åŠ é€’å½’é™åˆ¶è§£å†³LangGraphé™åˆ¶é—®é¢˜
            result = self.app.invoke(
                initial_state,
                config={
                    "recursion_limit": 100,  # å¢åŠ é€’å½’é™åˆ¶ï¼Œè§£å†³LangGraphé™åˆ¶é—®é¢˜
                    "configurable": {"thread_id": f"translation_{int(time.time())}"}
                }
            )
            
            if result['errors']:
                logger.warning("âš ï¸ ç¿»è¯‘è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯:")
                for error in result['errors']:
                    logger.warning(f"   - {error}")
            else:
                logger.info("ğŸ‰ ç¿»è¯‘å®Œæˆ!")
            
            logger.info(f"ğŸ“ åŒè¯­å­—å¹•æ–‡ä»¶: {result['output_file']}")
            return result['output_file']
            
        except Exception as e:
            logger.error(f"âŒ ç¿»è¯‘å¤±è´¥: {e}")
            raise


def main():
    """å‘½ä»¤è¡Œä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='SRTå­—å¹•ç¿»è¯‘Agent')
    parser.add_argument('input', help='è¾“å…¥SRTæ–‡ä»¶è·¯å¾„')
    parser.add_argument('-o', '--output', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('-s', '--source-lang', default='è‹±æ–‡', help='æºè¯­è¨€')
    parser.add_argument('-t', '--target-lang', default='ä¸­æ–‡', help='ç›®æ ‡è¯­è¨€')
    parser.add_argument('-m', '--model', default='gpt-3.5-turbo', 
                       help='LLMæ¨¡å‹')
    parser.add_argument('-b', '--batch-size', type=int, default=5,
                       help='æ‰¹é‡ç¿»è¯‘å¤§å°')
    parser.add_argument('--api-key', help='OpenAI APIå¯†é’¥')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(args.input):
        logger.error(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {args.input}")
        return 1
    
    # æ£€æŸ¥APIå¯†é’¥
    api_key = args.api_key or os.getenv("OPENAI_API_KEY")
    if not api_key:
        logger.error("âŒ è¯·è®¾ç½®OPENAI_API_KEYç¯å¢ƒå˜é‡æˆ–ä½¿ç”¨--api-keyå‚æ•°")
        return 1
    
    try:
        # åˆ›å»ºç¿»è¯‘Agent
        agent = SRTTranslatorAgent(
            llm_model=args.model,
            api_key=api_key,
            batch_size=args.batch_size
        )
        
        # æ‰§è¡Œç¿»è¯‘
        output_file = agent.translate_srt(
            input_file=args.input,
            output_file=args.output,
            source_lang=args.source_lang,
            target_lang=args.target_lang
        )
        
        logger.info(f"ğŸ‰ ç¿»è¯‘å®Œæˆ! è¾“å‡ºæ–‡ä»¶: {output_file}")
        return 0
        
    except Exception as e:
        logger.error(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        return 1


if __name__ == "__main__":
    exit(main()) 